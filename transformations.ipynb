{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representation\n",
    "- Multifractal analysis (1ere approche)\n",
    "\n",
    "- Discrete Fourier Transform (DFT) $\\checkmark$\n",
    "- Spectrogram\n",
    "- Autoregression $\\checkmark$\n",
    "- Shannon encoding $\\checkmark$\n",
    "- Wavelets (en cours)\n",
    "\n",
    "- Local symbolic features\n",
    "- SAX representation\n",
    "- Approximate entropy\n",
    "\n",
    "ML\n",
    "\n",
    "- Autoencoder\n",
    "\n",
    "- RNN\n",
    "- LSTM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install import_ipynb\n",
    "# %pip install  --user git+https://github.com/neurospin/pymultifracs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pywt\n",
    "from statsmodels.tsa.ar_model import AutoReg, ar_select_order\n",
    "import pymultifracs.mfa as mfa\n",
    "from pymultifracs.utils import build_q_log\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_to_batches(array, m):\n",
    "    \"\"\"\n",
    "    Transform an array of shape (n, p) into a list of arrays of shape (m, p).\n",
    "    \"\"\"\n",
    "    array = np.asarray(array)\n",
    "    p = array.shape[-1]\n",
    "    num_batches = p // m\n",
    "    return [array[i * m:(i + 1) * m] for i in range(num_batches)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=32):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim,128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, hidden_dim),\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, input_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "    def fit(self,X):\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        n_batch = 32\n",
    "        # Create a DataLoader for the dataset\n",
    "        X_tensor = torch.FloatTensor(X)\n",
    "        dataset = TensorDataset(X_tensor, X_tensor)\n",
    "        dataloader = DataLoader(dataset, batch_size=256, shuffle=True)\n",
    "        # Train the autoencoder\n",
    "        num_epochs = 50\n",
    "        for epoch in range(num_epochs):\n",
    "            for data in dataloader:\n",
    "                inputs, _ = data\n",
    "                inputs = inputs #.to(device)\n",
    "                outputs = self(inputs)\n",
    "                loss = criterion(outputs, inputs)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentityTransform:\n",
    "    @staticmethod\n",
    "    def transform(X, **kwargs):\n",
    "        return X\n",
    "\n",
    "class FourierTransform:\n",
    "    @staticmethod\n",
    "    def transform(X, new_dimension=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Return the fourier transform of size 'new_dimension'.\n",
    "        \"\"\"\n",
    "        fourier_transform = np.fft.fft(X, n=new_dimension,axis=-1)\n",
    "        modulus = np.abs(fourier_transform)\n",
    "        return modulus\n",
    "\n",
    "class LowFourierTransform:\n",
    "    @staticmethod\n",
    "    def transform(X, fs=250, cutoff_min=.3, cutoff_max = 4.5, n=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Fourier transform with a cutoff_ratio.\n",
    "\n",
    "        fs: sampling frequency\n",
    "        [cutoff_min, cutoff_max]: frequency interval that we consider\n",
    "        n: new_dimension before cutoff\n",
    "\n",
    "        Return the cutoff fourier transform.\n",
    "        \"\"\"\n",
    "        fourier_transform = np.fft.fft(X,n=n,axis=-1)\n",
    "        if n is None:\n",
    "            n = X.shape[1]\n",
    "        frequencies = np.fft.fftfreq(n, d=1/fs)\n",
    "        mask = (cutoff_min < frequencies) & (frequencies < cutoff_max)\n",
    "        fourier_transform = fourier_transform[:, mask]\n",
    "        modulus = np.abs(fourier_transform)\n",
    "        return modulus\n",
    "\n",
    "class LowPsdTransform:\n",
    "    @staticmethod\n",
    "    def transform(X, fs=250, cutoff_min=.3, cutoff_max = 4.5, n=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Power Spectrum Density with a cutoff_ratio.\n",
    "\n",
    "        fs: sampling frequency\n",
    "        [cutoff_min, cutoff_max]: frequency interval that we consider\n",
    "        n: new_dimension before cutoff\n",
    "\n",
    "        Return the cutoff power spectrum density (the fourier transform of the autocorrelation).\n",
    "        \"\"\"\n",
    "        fourier_transform = np.fft.fft(X, n=n, axis=-1)\n",
    "        if n is None:\n",
    "            n = X.shape[1]\n",
    "        frequencies = np.fft.fftfreq(n, d=1/fs)\n",
    "        mask = (cutoff_min < frequencies) & (frequencies < cutoff_max)\n",
    "        fourier_transform = fourier_transform[:, mask]\n",
    "        psd = fourier_transform * np.conj(fourier_transform)\n",
    "        return psd.real\n",
    "\n",
    "class WaveDecTransform:\n",
    "    @staticmethod\n",
    "    def transform(X, level=4, wavelet='db1', mode='symmetric', **kwargs):\n",
    "        \"\"\"\n",
    "        Multilevel decomposition\n",
    "        \"\"\"\n",
    "        array = np.array(X)\n",
    "        coeffs = pywt.wavedec(array, wavelet, mode=mode, level=level)\n",
    "        coeffs_torch = [torch.tensor(c) for c in coeffs[:1]]\n",
    "        return torch.cat(coeffs_torch, dim=-1)\n",
    "\n",
    "class DwtTransform:\n",
    "    @staticmethod\n",
    "    def transform(X, wavelet='db1', mode='symmetric', **kwargs):\n",
    "        \"\"\"\n",
    "        Single level decomposition (discrete)\n",
    "        \"\"\"\n",
    "        array = np.array(X)\n",
    "        coeffs = pywt.dwt(array, wavelet, mode=mode)\n",
    "        coeffs_torch = [torch.tensor(c) for c in coeffs[:1]]\n",
    "        return torch.cat(coeffs_torch, dim=-1)\n",
    "    \n",
    "class CwtTransform:\n",
    "    @staticmethod\n",
    "    def transform(X, scales = np.arange(1,100,20), wavelet='gaus1', pca_components = 10, **kwargs):\n",
    "        \"\"\"\n",
    "        Continuous Wavelet Transform followed by PCA\n",
    "        \"\"\"\n",
    "        array = np.array(X)\n",
    "        coeffs, freqs = pywt.cwt(array,scales= scales, wavelet=wavelet)\n",
    "        \n",
    "        coeffs = np.transpose(coeffs,(1,0,2) )\n",
    "        \n",
    "        mean_coefs = np.mean(np.abs(coeffs), axis=1)\n",
    "        std_coefs = np.std(np.abs(coeffs), axis=1)\n",
    "        features = np.concatenate((mean_coefs, std_coefs),axis=-1)\n",
    "        \n",
    "        pca = PCA(n_components=pca_components) \n",
    "        X_pca = pca.fit_transform(features)\n",
    "        return X_pca\n",
    "    \n",
    "class AutoRegTransform:\n",
    "    @staticmethod\n",
    "    def get_ar_coefficients(X, k=3, **kwargs):\n",
    "        \"\"\"\n",
    "        Perform an autoregression on each example, the coefficient of the autoregression are used in the representation of the signal.\n",
    "        \n",
    "        k: the number of coefficients computed\n",
    "        \"\"\"\n",
    "        n, p = X.shape\n",
    "        X = np.array(X)\n",
    "        ar_coefficients = np.zeros((n, k))\n",
    "        for i in range(n):\n",
    "            model = AutoReg(X[i], lags=k).fit()\n",
    "            ar_coefficients[i] = model.params[1:k+1]\n",
    "        return ar_coefficients\n",
    "\n",
    "    @staticmethod\n",
    "    def transform(X, k=3, **kwargs):\n",
    "        return AutoRegTransform.get_ar_coefficients(X, k)\n",
    "\n",
    "class ShannonEncodingTransform:\n",
    "    @staticmethod\n",
    "    def transform(X, level=4, wavelet='db1', mode='symmetric', **kwargs):\n",
    "        '''\n",
    "        Inspired by https://fr.mathworks.com/help/wavelet/ug/ecg-classification-using-wavelet-features.html\n",
    "\n",
    "        -> ECG Classification Using Wavelet Packet Entropy and Random Forests (https://www.mdpi.com/1099-4300/18/8/285)\n",
    "\n",
    "        '''\n",
    "        def compute_shannon_entropy(signal):\n",
    "            return -np.nansum(signal**2 * np.log(signal**2))\n",
    "        \n",
    "        n_examples = X.shape[0]\n",
    "        wp = pywt.WaveletPacket(X[0, :], wavelet=\"sym8\", maxlevel=3)\n",
    "        packet_names = [node.path for node in wp.get_level(3, \"natural\")]\n",
    "        \n",
    "        feature_matrix_wav_packet_entropy = np.full((n_examples, 8), np.nan)\n",
    "        for i in range(len(X)):\n",
    "            wp = pywt.WaveletPacket(X[i, :], wavelet=\"sym8\", maxlevel=3)\n",
    "            for j in range(len(packet_names)):\n",
    "                new_wp = pywt.WaveletPacket(data=None, wavelet=\"sym8\", maxlevel=3)\n",
    "                new_wp[packet_names[j]] = wp[packet_names[j]].data\n",
    "                reconstructed_signal = new_wp.reconstruct(update=False)\n",
    "                feature_matrix_wav_packet_entropy[i, j] = compute_shannon_entropy(reconstructed_signal)\n",
    "        return feature_matrix_wav_packet_entropy\n",
    "\n",
    "class WaveletLeadersTransform:\n",
    "    @staticmethod\n",
    "    def transform(X, j1=2, j2=4, **kwargs):\n",
    "        '''\n",
    "        Use the multifractal framework.\n",
    "        The representation obtained is inspired by https://fr.mathworks.com/help/wavelet/ug/ecg-classification-using-wavelet-features.html:\n",
    "        [ width of the singularity spectrum = degree of multifractality, log_cumulants[0]]\n",
    "        \n",
    "        '''\n",
    "        n = X.shape[0] if X.ndim > 1 else 1\n",
    "        transformed_X = -np.ones((n, 2))\n",
    "        for i in range(X.shape[0]):\n",
    "            # print(i)\n",
    "            dwt, lwt = mfa.mf_analysis_full(\n",
    "                X[i],\n",
    "                scaling_ranges=[(j1, j2)],\n",
    "                q=build_q_log(1, 10, 20),\n",
    "                n_cumul=2,\n",
    "                p_exp=np.inf,\n",
    "                gamint=0.0\n",
    "            )\n",
    "            sf, cumul, mfs, hmin = lwt\n",
    "            transformed_X[i, :] = sf.H.item(), cumul.log_cumulants[1].item()\n",
    "        return transformed_X\n",
    "\n",
    "class MultiFracsTransform:\n",
    "    @staticmethod\n",
    "    def transform(X, j1=2, j2=4, **kwargs):\n",
    "        '''\n",
    "        Use the multifractal framework.\n",
    "        The representation obtained is inspired by HRVMultiScaling_ivanov1999:\n",
    "        [degree of multifractality, tau(3), X[i].std()]\n",
    "        where tau(3) is characterizing the scaling of the third moment Z_3(a).\n",
    "        '''\n",
    "        n = X.shape[0] if X.ndim > 1 else 1\n",
    "        transformed_X = -np.ones((n, 3))\n",
    "        for i in range(X.shape[0]):\n",
    "            dwt, lwt = mfa.mf_analysis_full(\n",
    "                X[i],\n",
    "                scaling_ranges=[(j1, j2)],\n",
    "                q=build_q_log(1, 10, 20),\n",
    "                n_cumul=2,\n",
    "                p_exp=np.inf,\n",
    "                gamint=0.0\n",
    "            )\n",
    "            sf, cumul, mfs, hmin = lwt\n",
    "            tau = interp1d(sf.q, sf.zeta[:,0,0], kind='linear')\n",
    "            degree_of_multifractality = np.max(mfs.hq) - np.min(mfs.hq)\n",
    "            transformed_X[i, :] = degree_of_multifractality, tau(3).item(), X[i].std()\n",
    "        return transformed_X\n",
    "\n",
    "class CrossCorTransform:\n",
    "    @staticmethod\n",
    "    def transform(X, new_dim=10, **kwargs):\n",
    "        \"\"\"\n",
    "        Compute the cross covariance between examples and then do PCA.\n",
    "        \"\"\"\n",
    "        crosscor = np.corrcoef(X)\n",
    "\n",
    "        pca = PCA(n_components=new_dim)\n",
    "        transformed_data = pca.fit_transform(crosscor)\n",
    "        return transformed_data# , pca.components_\n",
    "        \n",
    "        # eigen_values, eigen_vectors = np.linalg.eigh(crosscor)\n",
    "        \n",
    "        # return transformed_X\n",
    "\n",
    "class AutoCorTransform:\n",
    "    @staticmethod\n",
    "    def transform(X, k=4, m=10, **kwargs):\n",
    "        \"\"\"\n",
    "        Weird improvisation, does not work\n",
    "        \"\"\"\n",
    "        \n",
    "        n = X.shape[0] if X.ndim > 1 else 1\n",
    "        transformed_X = list()\n",
    "        for i in range(X.shape[0]):\n",
    "            batches = reshape_to_batches(X[i],m)\n",
    "            \n",
    "            autocor = np.corrcoef(batches)\n",
    "            # print(autocor.shape)\n",
    "            pca = PCA(n_components=k)\n",
    "            transformed_data = pca.fit_transform(autocor)\n",
    "            transformed_X.append(pca.components_.flatten())\n",
    "            \n",
    "        return np.array(transformed_X)\n",
    "    \n",
    "class AutoEncoderTransform:\n",
    "    @staticmethod\n",
    "    def transform(X, mode = 'n-pretrained', fourier_transform = False, n_fourier = 128, dim_encoder = 16, **kwargs):\n",
    "        \"\"\"\n",
    "        AutoEncoder Transform\n",
    "        \"\"\"\n",
    "        n = 200\n",
    "        if mode == 'pretrained':\n",
    "            fX = torch.fft.fft(torch.FloatTensor(X),n = n)\n",
    "            X = (fX  * torch.conj(fX)).real\n",
    "            autoencoder = AutoEncoder(n,10)\n",
    "            autoencoder.load_state_dict(torch.load('autoencoder_state_dict.pth'))\n",
    "            autoencoder.eval()  # Set the model to evaluation mode\n",
    "            return autoencoder.encoder(X).detach().numpy()\n",
    "        \n",
    "        else:\n",
    "            if fourier_transform:# PSD  \n",
    "                fX = torch.fft.fft(torch.FloatTensor(X), n=n_fourier)\n",
    "                X = (fX  * torch.conj(fX)).real\n",
    "            X = torch.FloatTensor(X)\n",
    "            n = X.shape[-1]\n",
    "            autoencoder = AutoEncoder(n,dim_encoder)\n",
    "            autoencoder.fit(X)\n",
    "            autoencoder.eval()  # Set the model to evaluation mode\n",
    "            return autoencoder.encoder(X).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformationRegistry:\n",
    "    def __init__(self):\n",
    "        self.transformations = {}\n",
    "\n",
    "    def register(self, name, transform_class):\n",
    "        self.transformations[name] = transform_class\n",
    "\n",
    "    def get(self, name):\n",
    "        transform_class = self.transformations.get(name)\n",
    "        if transform_class is None:\n",
    "            raise ValueError(f\"Transformation {name} not recognized.\")\n",
    "        return transform_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransform:\n",
    "    def __init__(self, registry, save_data = True,verbose = True):\n",
    "        self.registry = registry\n",
    "\n",
    "        self.save_data = save_data\n",
    "        self.data = {}\n",
    "\n",
    "    @staticmethod\n",
    "    def handle_trans_kwargs(input):\n",
    "        '''\n",
    "        input: [str, dict] or [str] or str\n",
    "        Return: str, dict or str, {}\n",
    "        '''\n",
    "        if isinstance(input, list):\n",
    "            if len(input) == 2 and isinstance(input[0], str) and isinstance(input[1], dict):\n",
    "                return input[0], input[1]\n",
    "            elif len(input) == 1 and isinstance(input[0], str):\n",
    "                return input[0], {}\n",
    "            else:\n",
    "                raise ValueError(\"Invalid list input. Expected [str, dict] or [str].\")\n",
    "        elif isinstance(input, str):\n",
    "            return input, {}\n",
    "        else:\n",
    "            raise ValueError(\"Invalid input type. Expected [str, dict], [str], or str.\")\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_trans_kwargs_str(trans_name, kwargs):\n",
    "        def str_dict(dictionnary):\n",
    "            res = ''\n",
    "            for key,value in dictionnary.items():\n",
    "                res+=f'{key}={value}_'\n",
    "            return res\n",
    "        return (trans_name + '_' + str_dict(kwargs) )[:-1]\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_full_trans_kwargs_str(transformation):\n",
    "        # print(transformation)\n",
    "        res =''\n",
    "        transformation = DataTransform.sanitize_transformations(transformation)\n",
    "        for trans in transformation:\n",
    "            res += DataTransform.get_trans_kwargs_str(*DataTransform.handle_trans_kwargs(trans))+'_'\n",
    "        \n",
    "        return res[:-1]\n",
    "    \n",
    "    @staticmethod\n",
    "    def sanitize_transformations(transformations):\n",
    "        if isinstance(transformations, str):\n",
    "            sanitized_transformations = [[transformations]]\n",
    "        elif isinstance(transformations, list) and len(transformations) == 2 and isinstance(transformations[0], str) and isinstance(transformations[1], dict):\n",
    "            sanitized_transformations = [transformations]\n",
    "\n",
    "        elif isinstance(transformations, list):\n",
    "            sanitized_transformations = []\n",
    "            for item in transformations:\n",
    "                if isinstance(item, str):\n",
    "                    sanitized_transformations.append([item])\n",
    "                elif isinstance(item, list) and len(item) == 2 and isinstance(item[0], str) and isinstance(item[1], dict):\n",
    "                    sanitized_transformations.append(item)\n",
    "                elif isinstance(item, list) and len(item) == 1 and isinstance(item[0], str):\n",
    "                    sanitized_transformations.append(item)\n",
    "                else:\n",
    "                    raise ValueError(\"Invalid list input. Expected [str, dict] or [str].\")\n",
    "        return sanitized_transformations\n",
    "    \n",
    "    def apply_transformation(self, X, transformations):      #, **kwargs):\n",
    "        '''\n",
    "        X: data\n",
    "        transformations: [str, [str, dict], [str], ...] or [str] or str\n",
    "        '''\n",
    "        # if isinstance(transformations, str):\n",
    "        #     sanitized_transformations = [[transformations]]\n",
    "        # elif isinstance(transformations, list) and len(transformations) == 2 and isinstance(transformations[0], str) and isinstance(transformations[1], dict):\n",
    "        #     sanitized_transformations = [transformations]\n",
    "\n",
    "        # elif isinstance(transformations, list):\n",
    "        #     sanitized_transformations = []\n",
    "        #     for item in transformations:\n",
    "        #         if isinstance(item, str):\n",
    "        #             sanitized_transformations.append([item])\n",
    "        #         elif isinstance(item, list) and len(item) == 2 and isinstance(item[0], str) and isinstance(item[1], dict):\n",
    "        #             sanitized_transformations.append(item)\n",
    "        #         elif isinstance(item, list) and len(item) == 1 and isinstance(item[0], str):\n",
    "        #             sanitized_transformations.append(item)\n",
    "        #         else:\n",
    "        #             raise ValueError(\"Invalid list input. Expected [str, dict] or [str].\")\n",
    "    \n",
    "        sanitized_transformations = DataTransform.sanitize_transformations(transformations)\n",
    "        transformed_parts = []\n",
    "        for transformation in sanitized_transformations:\n",
    "            trans_name, kwargs = DataTransform.handle_trans_kwargs(transformation)\n",
    "            trans_name_kwargs = DataTransform.get_trans_kwargs_str(trans_name, kwargs)\n",
    "\n",
    "            if self.save_data and (trans_name_kwargs in self.data.keys()):\n",
    "                transformed_parts.append(self.data[trans_name_kwargs])\n",
    "            else:\n",
    "                transform_class = self.registry.get(trans_name)\n",
    "                print(f'Computing  {trans_name_kwargs} ...', end='', flush=True)\n",
    "                transformed_part = transform_class.transform(X, **kwargs)\n",
    "                print('\\r' + ' ' * len(f'Computing  {trans_name} ...') + '\\r', end='')\n",
    "                self.data[trans_name_kwargs] = transformed_part\n",
    "                transformed_parts.append(transformed_part)\n",
    "\n",
    "        return np.concatenate(transformed_parts, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Initialize the registry\n",
    "    registry = TransformationRegistry()\n",
    "\n",
    "    # Register transformations\n",
    "    registry.register('identity', IdentityTransform)\n",
    "    registry.register('fourier', FourierTransform)\n",
    "    registry.register('low_fourier', LowFourierTransform)\n",
    "    registry.register('low_psd', LowPsdTransform)\n",
    "    registry.register('wavedec', WaveDecTransform)\n",
    "    registry.register('dwt', DwtTransform)\n",
    "    registry.register('cwt', CwtTransform)\n",
    "    registry.register('autoreg', AutoRegTransform)\n",
    "    registry.register('shannon_encoding', ShannonEncodingTransform)\n",
    "    registry.register('wavelet_leaders', WaveletLeadersTransform)\n",
    "    registry.register('multifracs', MultiFracsTransform)\n",
    "    registry.register('crosscor', CrossCorTransform)\n",
    "    registry.register('autocor', AutoCorTransform)\n",
    "    registry.register('autoencoder', AutoEncoderTransform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation: identity, Shape: (100, 150)\n",
      "Transformation: fourier, Shape: (100, 150)\n",
      "Transformation: low_fourier, Shape: (100, 2)\n",
      "Transformation: low_psd, Shape: (100, 2)\n",
      "Transformation: wavedec, Shape: (100, 10)\n",
      "Transformation: dwt, Shape: (100, 75)\n",
      "Transformation: cwt, Shape: (100, 10)\n",
      "Transformation: autoreg, Shape: (100, 3)\n",
      "Transformation: shannon_encoding, Shape: (100, 8)\n",
      "Transformation: wavelet_leaders, Shape: (100, 2)\n",
      "Transformation: multifracs, Shape: (100, 3)\n",
      "Transformation: crosscor, Shape: (100, 10)\n",
      "Transformation: autocor, Shape: (100, 60)\n",
      "Transformation: autoencoder, Shape: (100, 16)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Initialize the data transformer\n",
    "    data_transformer = DataTransform(registry)\n",
    "\n",
    "    # Example input data\n",
    "    X = np.random.randn(100, 150)  # Example input data\n",
    "    y = np.random.randint(0, 2, 100)  # Example labels\n",
    "    \n",
    "    for trans_names in registry.transformations.keys():\n",
    "        trans_names_str = [str(name) for name in trans_names]\n",
    "        trans_name_str = '+'.join(trans_names_str) if isinstance(trans_names, list) else trans_names\n",
    "        kwargs = trans_names[1] if isinstance(trans_names, list) and len(trans_names) > 1 else {}\n",
    "        trans_names = trans_names[0] if isinstance(trans_names, list) else trans_names\n",
    "        \n",
    "        # Apply transformation\n",
    "        transformed_X = data_transformer.apply_transformation(X, trans_names, **kwargs)\n",
    "        \n",
    "        print(f\"Transformation: {trans_name_str}, Shape: {transformed_X.shape}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation: identity, Classifier: SVM, Mean Accuracy: 0.530, Std Dev: 0.068\n",
      "Transformation: identity, Classifier: DecisionTree, Mean Accuracy: 0.530, Std Dev: 0.040\n",
      "Transformation: identity, Classifier: RandomForest, Mean Accuracy: 0.590, Std Dev: 0.107\n",
      "Transformation: crosscor, Classifier: SVM, Mean Accuracy: 0.480, Std Dev: 0.112\n",
      "Transformation: crosscor, Classifier: DecisionTree, Mean Accuracy: 0.500, Std Dev: 0.063\n",
      "Transformation: crosscor, Classifier: RandomForest, Mean Accuracy: 0.520, Std Dev: 0.160\n",
      "Transformation: autocor_m=4_k=4, Classifier: SVM, Mean Accuracy: 0.430, Std Dev: 0.060\n",
      "Transformation: autocor_m=4_k=4, Classifier: DecisionTree, Mean Accuracy: 0.510, Std Dev: 0.102\n",
      "Transformation: autocor_m=4_k=4, Classifier: RandomForest, Mean Accuracy: 0.480, Std Dev: 0.075\n",
      "Transformation: fourier_crosscor, Classifier: SVM, Mean Accuracy: 0.630, Std Dev: 0.098\n",
      "Transformation: fourier_crosscor, Classifier: DecisionTree, Mean Accuracy: 0.500, Std Dev: 0.055\n",
      "Transformation: fourier_crosscor, Classifier: RandomForest, Mean Accuracy: 0.560, Std Dev: 0.097\n",
      "Transformation: wavedec, Classifier: SVM, Mean Accuracy: 0.570, Std Dev: 0.051\n",
      "Transformation: wavedec, Classifier: DecisionTree, Mean Accuracy: 0.500, Std Dev: 0.084\n",
      "Transformation: wavedec, Classifier: RandomForest, Mean Accuracy: 0.550, Std Dev: 0.071\n",
      "Transformation: autoreg_k=3, Classifier: SVM, Mean Accuracy: 0.470, Std Dev: 0.024\n",
      "Transformation: autoreg_k=3, Classifier: DecisionTree, Mean Accuracy: 0.490, Std Dev: 0.097\n",
      "Transformation: autoreg_k=3, Classifier: RandomForest, Mean Accuracy: 0.470, Std Dev: 0.103\n",
      "Transformation: identity, Classifier: SVM, Mean Accuracy: 0.530, Std Dev: 0.068\n",
      "Transformation: identity, Classifier: DecisionTree, Mean Accuracy: 0.530, Std Dev: 0.040\n",
      "Transformation: identity, Classifier: RandomForest, Mean Accuracy: 0.590, Std Dev: 0.107\n",
      "Transformation: crosscor, Classifier: SVM, Mean Accuracy: 0.480, Std Dev: 0.112\n",
      "Transformation: crosscor, Classifier: DecisionTree, Mean Accuracy: 0.500, Std Dev: 0.063\n",
      "Transformation: crosscor, Classifier: RandomForest, Mean Accuracy: 0.520, Std Dev: 0.160\n",
      "Transformation: autocor_m=4_k=4, Classifier: SVM, Mean Accuracy: 0.430, Std Dev: 0.060\n",
      "Transformation: autocor_m=4_k=4, Classifier: DecisionTree, Mean Accuracy: 0.510, Std Dev: 0.102\n",
      "Transformation: autocor_m=4_k=4, Classifier: RandomForest, Mean Accuracy: 0.480, Std Dev: 0.075\n",
      "Transformation: fourier_crosscor, Classifier: SVM, Mean Accuracy: 0.630, Std Dev: 0.098\n",
      "Transformation: fourier_crosscor, Classifier: DecisionTree, Mean Accuracy: 0.500, Std Dev: 0.055\n",
      "Transformation: fourier_crosscor, Classifier: RandomForest, Mean Accuracy: 0.560, Std Dev: 0.097\n",
      "Transformation: wavedec, Classifier: SVM, Mean Accuracy: 0.570, Std Dev: 0.051\n",
      "Transformation: wavedec, Classifier: DecisionTree, Mean Accuracy: 0.500, Std Dev: 0.084\n",
      "Transformation: wavedec, Classifier: RandomForest, Mean Accuracy: 0.550, Std Dev: 0.071\n",
      "Transformation: autoreg_k=3, Classifier: SVM, Mean Accuracy: 0.470, Std Dev: 0.024\n",
      "Transformation: autoreg_k=3, Classifier: DecisionTree, Mean Accuracy: 0.490, Std Dev: 0.097\n",
      "Transformation: autoreg_k=3, Classifier: RandomForest, Mean Accuracy: 0.470, Std Dev: 0.103\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    \n",
    "\n",
    "    # Define the classifiers to be tested\n",
    "    classifiers = {\n",
    "        'SVM': SVC(),\n",
    "        'DecisionTree': DecisionTreeClassifier(),\n",
    "        'RandomForest': RandomForestClassifier()\n",
    "    }\n",
    "\n",
    "    # Define the transformations to be tested\n",
    "    transformations = [\n",
    "        'identity',\n",
    "        ['crosscor'],\n",
    "        ['autocor',{'m':4,'k':4}],\n",
    "        [['fourier'],['crosscor']],\n",
    "        ['wavedec'],\n",
    "        ['autoreg', {'k': 3}]\n",
    "    ]\n",
    "\n",
    "    \n",
    "\n",
    "    # Function to evaluate a classifier using cross-validation\n",
    "    def evaluate_classifier_cv(classifier, X, y):\n",
    "        scores = cross_val_score(classifier, X, y, cv=5)  # 5-fold cross-validation\n",
    "        return np.mean(scores), np.std(scores)\n",
    "\n",
    "    # Loop over each transformation and each classifier\n",
    "    results = {}\n",
    "\n",
    "    for trans in transformations:\n",
    "\n",
    "        trans_name_str = DataTransform.get_full_trans_kwargs_str(trans)\n",
    "        # trans_name_str = '+'.join(trans_names_str) if isinstance(trans_names, list) else trans_names\n",
    "        # kwargs = trans_names[1] if isinstance(trans_names, list) and len(trans_names) > 1 else {}\n",
    "        # trans_names = trans_names[0] if isinstance(trans_names, list) else trans_names\n",
    "        \n",
    "        # Apply transformation\n",
    "        # print(trans)\n",
    "        transformed_X = data_transformer.apply_transformation(X, trans)\n",
    "        # Standardize the data (important for some classifiers like SVM)\n",
    "        scaler = StandardScaler()\n",
    "        transformed_X = scaler.fit_transform(transformed_X)\n",
    "        \n",
    "        results[trans_name_str] = {}\n",
    "        for clf_name, clf in classifiers.items():\n",
    "            # Evaluate the classifier with cross-validation\n",
    "            mean_accuracy, std_accuracy = evaluate_classifier_cv(clf, transformed_X, y)\n",
    "            results[trans_name_str][clf_name] = (mean_accuracy, std_accuracy)\n",
    "            print(f\"Transformation: {trans_name_str}, Classifier: {clf_name}, Mean Accuracy: {mean_accuracy:.3f}, Std Dev: {std_accuracy:.3f}\")\n",
    "\n",
    "    # Print the results\n",
    "    for trans_name, clf_results in results.items():\n",
    "        for clf_name, (mean_accuracy, std_accuracy) in clf_results.items():\n",
    "            print(f\"Transformation: {trans_name}, Classifier: {clf_name}, Mean Accuracy: {mean_accuracy:.3f}, Std Dev: {std_accuracy:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1                         ...\n",
      "2                         ...\n",
      "3                         ...\n",
      "4                         ...\n",
      "Computing  multifracs_i=4 ..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aejog\\anaconda3\\Lib\\site-packages\\pymultifracs\\utils.py:87: RuntimeWarning: divide by zero encountered in power\n",
      "  return np.power(array, exponent)\n",
      "c:\\Users\\aejog\\anaconda3\\Lib\\site-packages\\pymultifracs\\utils.py:76: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  return array ** exponent\n",
      "c:\\Users\\aejog\\anaconda3\\Lib\\site-packages\\pymultifracs\\cumulants.py:265: RuntimeWarning: divide by zero encountered in log\n",
      "  log_T_X_j = np.log(T_X_j)\n",
      "c:\\Users\\aejog\\anaconda3\\Lib\\site-packages\\pymultifracs\\mfspectrum.py:117: RuntimeWarning: invalid value encountered in divide\n",
      "  R_j = temp / Z\n",
      "c:\\Users\\aejog\\anaconda3\\Lib\\site-packages\\pymultifracs\\mfspectrum.py:118: RuntimeWarning: divide by zero encountered in log2\n",
      "  V[:, ind_j, :] = fixednansum(R_j * np.log2(mrq_values_j), axis=1)\n",
      "c:\\Users\\aejog\\anaconda3\\Lib\\site-packages\\pymultifracs\\mfspectrum.py:118: RuntimeWarning: invalid value encountered in multiply\n",
      "  V[:, ind_j, :] = fixednansum(R_j * np.log2(mrq_values_j), axis=1)\n",
      "c:\\Users\\aejog\\anaconda3\\Lib\\site-packages\\pymultifracs\\mfspectrum.py:119: RuntimeWarning: divide by zero encountered in log2\n",
      "  U[:, ind_j, :] = np.log2(nj) + fixednansum((R_j * np.log2(R_j)),\n",
      "c:\\Users\\aejog\\anaconda3\\Lib\\site-packages\\pymultifracs\\mfspectrum.py:119: RuntimeWarning: invalid value encountered in multiply\n",
      "  U[:, ind_j, :] = np.log2(nj) + fixednansum((R_j * np.log2(R_j)),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5                        \n",
      "6                         ...\n",
      "7                         ...\n",
      "8                         ...\n",
      "9                         ...\n",
      "10                        ...\n",
      "11                       0 ...\n",
      "12                       1 ...\n",
      "13                       2 ...\n",
      "14                       3 ...\n",
      "15                       4 ...\n",
      "16                       5 ...\n",
      "17                       6 ...\n",
      "18                       7 ...\n",
      "19                       8 ...\n",
      "20                       9 ...\n",
      "Computing  multifracs_i=20 ..."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# Apply transformation\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[1;32m---> 14\u001b[0m     transformed_X \u001b[38;5;241m=\u001b[39m data_transformer\u001b[38;5;241m.\u001b[39mapply_transformation(X[i,:][\u001b[38;5;28;01mNone\u001b[39;00m,:], [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmultifracs\u001b[39m\u001b[38;5;124m'\u001b[39m,{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m'\u001b[39m:i}])\n",
      "Cell \u001b[1;32mIn[23], line 98\u001b[0m, in \u001b[0;36mDataTransform.apply_transformation\u001b[1;34m(self, X, transformations)\u001b[0m\n\u001b[0;32m     96\u001b[0m transform_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregistry\u001b[38;5;241m.\u001b[39mget(trans_name)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComputing  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrans_name_kwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ...\u001b[39m\u001b[38;5;124m'\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 98\u001b[0m transformed_part \u001b[38;5;241m=\u001b[39m transform_class\u001b[38;5;241m.\u001b[39mtransform(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComputing  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrans_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ...\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m'\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[trans_name_kwargs] \u001b[38;5;241m=\u001b[39m transformed_part\n",
      "Cell \u001b[1;32mIn[21], line 177\u001b[0m, in \u001b[0;36mMultiFracsTransform.transform\u001b[1;34m(X, j1, j2, **kwargs)\u001b[0m\n\u001b[0;32m    175\u001b[0m transformed_X \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39mones((n, \u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m--> 177\u001b[0m     dwt, lwt \u001b[38;5;241m=\u001b[39m mfa\u001b[38;5;241m.\u001b[39mmf_analysis_full(\n\u001b[0;32m    178\u001b[0m         X[i],\n\u001b[0;32m    179\u001b[0m         scaling_ranges\u001b[38;5;241m=\u001b[39m[(j1, j2)],\n\u001b[0;32m    180\u001b[0m         q\u001b[38;5;241m=\u001b[39mbuild_q_log(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m),\n\u001b[0;32m    181\u001b[0m         n_cumul\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    182\u001b[0m         p_exp\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39minf,\n\u001b[0;32m    183\u001b[0m         gamint\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m    184\u001b[0m     )\n\u001b[0;32m    185\u001b[0m     sf, cumul, mfs, hmin \u001b[38;5;241m=\u001b[39m lwt\n\u001b[0;32m    186\u001b[0m     tau \u001b[38;5;241m=\u001b[39m interp1d(sf\u001b[38;5;241m.\u001b[39mq, sf\u001b[38;5;241m.\u001b[39mzeta[:,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m], kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\aejog\\anaconda3\\Lib\\site-packages\\pymultifracs\\mfa.py:184\u001b[0m, in \u001b[0;36mmf_analysis_full\u001b[1;34m(signal, scaling_ranges, normalization, gamint, weighted, wt_name, p_exp, q, n_cumul, bootstrap_weighted, estimates, R)\u001b[0m\n\u001b[0;32m    181\u001b[0m j1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m([sr[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m sr \u001b[38;5;129;01min\u001b[39;00m scaling_ranges])\n\u001b[0;32m    182\u001b[0m j2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m([sr[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m sr \u001b[38;5;129;01min\u001b[39;00m scaling_ranges])\n\u001b[1;32m--> 184\u001b[0m wt_transform \u001b[38;5;241m=\u001b[39m wavelet_analysis(signal, p_exp\u001b[38;5;241m=\u001b[39mp_exp, wt_name\u001b[38;5;241m=\u001b[39mwt_name,\n\u001b[0;32m    185\u001b[0m                                 j1\u001b[38;5;241m=\u001b[39mj1, j2\u001b[38;5;241m=\u001b[39mj2, gamint\u001b[38;5;241m=\u001b[39mgamint, j2_reg\u001b[38;5;241m=\u001b[39mj2,\n\u001b[0;32m    186\u001b[0m                                 normalization\u001b[38;5;241m=\u001b[39mnormalization,\n\u001b[0;32m    187\u001b[0m                                 weighted\u001b[38;5;241m=\u001b[39mweighted)\n\u001b[0;32m    189\u001b[0m mrq \u001b[38;5;241m=\u001b[39m wt_transform\u001b[38;5;241m.\u001b[39mwt_coefs\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wt_transform\u001b[38;5;241m.\u001b[39mwt_leaders \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\aejog\\anaconda3\\Lib\\site-packages\\pymultifracs\\wavelet.py:568\u001b[0m, in \u001b[0;36mwavelet_analysis\u001b[1;34m(signal, p_exp, wt_name, j1, j2, gamint, normalization, weighted, j2_reg)\u001b[0m\n\u001b[0;32m    564\u001b[0m sans_voisin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m scale \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, max_level \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 568\u001b[0m     detail, approx \u001b[38;5;241m=\u001b[39m filtering(approx, high_filter, low_filter)\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# normalization\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     detail \u001b[38;5;241m=\u001b[39m detail\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(scale\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m0.5\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mnormalization))\n",
      "File \u001b[1;32mc:\\Users\\aejog\\anaconda3\\Lib\\site-packages\\pymultifracs\\wavelet.py:149\u001b[0m, in \u001b[0;36mfiltering\u001b[1;34m(approx, high_filter, low_filter)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;66;03m# apply filters\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# note: 'direct' method MUST be used, since there are elements\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m# that are np.inf inside `approx`\u001b[39;00m\n\u001b[0;32m    148\u001b[0m high \u001b[38;5;241m=\u001b[39m convolve(approx, high_filter, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m'\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdirect\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 149\u001b[0m low \u001b[38;5;241m=\u001b[39m convolve(approx, low_filter, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m'\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdirect\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m# high[np.isnan(high)] = np.inf\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;66;03m# low[np.isnan(low)] = np.inf\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \n\u001b[0;32m    154\u001b[0m \u001b[38;5;66;03m# index of first good value\u001b[39;00m\n\u001b[0;32m    155\u001b[0m fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(high_filter) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\aejog\\anaconda3\\Lib\\site-packages\\scipy\\signal\\_signaltools.py:1431\u001b[0m, in \u001b[0;36mconvolve\u001b[1;34m(in1, in2, mode, method)\u001b[0m\n\u001b[0;32m   1428\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _np_conv_ok(volume, kernel, mode):\n\u001b[0;32m   1429\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mconvolve(volume, kernel, mode)\n\u001b[1;32m-> 1431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m correlate(volume, _reverse_and_conj(kernel), mode, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdirect\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1433\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAcceptable method flags are \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1434\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdirect\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfft\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\aejog\\anaconda3\\Lib\\site-packages\\scipy\\signal\\_signaltools.py:271\u001b[0m, in \u001b[0;36mcorrelate\u001b[1;34m(in1, in2, mode, method)\u001b[0m\n\u001b[0;32m    269\u001b[0m in1zpadded \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(ps, in1\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    270\u001b[0m sc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;241m0\u001b[39m, i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m in1\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m--> 271\u001b[0m in1zpadded[sc] \u001b[38;5;241m=\u001b[39m in1\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    274\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(ps, in1\u001b[38;5;241m.\u001b[39mdtype)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Initialize the data transformer\n",
    "    data_transformer = DataTransform(registry)\n",
    "\n",
    "    # Example input data\n",
    "    data = np.load('ecgs_labels.npy')\n",
    "    X, y = data[:,:-1], data[:,-1] # Example input data\n",
    "    p = np.random.permutation(X.shape[0])\n",
    "    X = X[p,:]\n",
    "    y =y[p]\n",
    "    for i in range(X.shape[0]):\n",
    "        # Apply transformation\n",
    "        print(i)\n",
    "        transformed_X = data_transformer.apply_transformation(X[i,:][None,:], ['multifracs',{'i':i}])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
