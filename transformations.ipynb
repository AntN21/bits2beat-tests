{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representation\n",
    "- Multifractal analysis (1ere approche)\n",
    "\n",
    "- Discrete Fourier Transform (DFT) $\\checkmark$\n",
    "- Spectrogram\n",
    "- Autoregression $\\checkmark$\n",
    "- Shannon encoding $\\checkmark$\n",
    "- Wavelets (en cours)\n",
    "\n",
    "- Local symbolic features\n",
    "- SAX representation\n",
    "- Approximate entropy\n",
    "\n",
    "ML\n",
    "\n",
    "- Autoencoder\n",
    "\n",
    "- RNN\n",
    "- LSTM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install import_ipynb\n",
    "# %pip install  --user git+https://github.com/neurospin/pymultifracs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pywt\n",
    "from statsmodels.tsa.ar_model import AutoReg, ar_select_order\n",
    "import pymultifracs.mfa as mfa\n",
    "from pymultifracs.utils import build_q_log\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_to_batches(array, m):\n",
    "    \"\"\"\n",
    "    Transform an array of shape (n, p) into a list of arrays of shape (m, p).\n",
    "    \"\"\"\n",
    "    array = np.asarray(array)\n",
    "    p = array.shape[-1]\n",
    "    num_batches = p // m\n",
    "    return [array[i * m:(i + 1) * m] for i in range(num_batches)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentityTransform:\n",
    "    @staticmethod\n",
    "    def transform(X, **kwargs):\n",
    "        return X\n",
    "\n",
    "class FourierTransform:\n",
    "    @staticmethod\n",
    "    def transform(X, new_dimension=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Return the fourier transform of size 'new_dimension'.\n",
    "        \"\"\"\n",
    "        fourier_transform = np.fft.fft(X, n=new_dimension,axis=-1)\n",
    "        modulus = np.abs(fourier_transform)\n",
    "        return modulus\n",
    "\n",
    "class LowFourierTransform:\n",
    "    @staticmethod\n",
    "    def transform(X, fs=250, cutoff_ratio=.3, n=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Fourier transform with a cutoff_ratio.\n",
    "\n",
    "        fs: sampling frequency\n",
    "        cutoff_ratio: frequency over which we do not consider the value\n",
    "        n: new_dimension before cutoff\n",
    "\n",
    "        Return the cutoff fourier transform.\n",
    "        \"\"\"\n",
    "        fourier_transform = np.fft.fft(X,n=n,axis=-1)\n",
    "        if n is None:\n",
    "            n = X.shape[1]\n",
    "        frequencies = np.fft.fftfreq(n, d=1/fs)\n",
    "        mask = frequencies < cutoff_ratio\n",
    "        fourier_transform = fourier_transform[:, mask]\n",
    "        modulus = np.abs(fourier_transform)\n",
    "        return modulus\n",
    "\n",
    "class LowPsdTransform:\n",
    "    @staticmethod\n",
    "    def transform(X, fs=250, cutoff_ratio=.3, n=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Power Spectrum Density with a cutoff_ratio.\n",
    "\n",
    "        fs: sampling frequency\n",
    "        cutoff_ratio: frequency over which we do not consider the value\n",
    "        n: new_dimension before cutoff\n",
    "\n",
    "        Return the cutoff power spectrum density (the fourier transform of the autocorrelation).\n",
    "        \"\"\"\n",
    "        fourier_transform = np.fft.fft(X, n=n, axis=-1)\n",
    "        if n is None:\n",
    "            n = X.shape[1]\n",
    "        frequencies = np.fft.fftfreq(n, d=1/fs)\n",
    "        mask = frequencies < cutoff_ratio\n",
    "        fourier_transform = fourier_transform[:, mask]\n",
    "        psd = fourier_transform * np.conj(fourier_transform)\n",
    "        return psd.real\n",
    "\n",
    "class WaveDecTransform:\n",
    "    @staticmethod\n",
    "    def transform(X, level=4, wavelet='db1', mode='symmetric', **kwargs):\n",
    "        \"\"\"\n",
    "        Multilevel decomposition\n",
    "        \"\"\"\n",
    "        array = np.array(X)\n",
    "        coeffs = pywt.wavedec(array, wavelet, mode=mode, level=level)\n",
    "        coeffs_torch = [torch.tensor(c) for c in coeffs[:1]]\n",
    "        return torch.cat(coeffs_torch, dim=-1)\n",
    "\n",
    "class DwtTransform:\n",
    "    @staticmethod\n",
    "    def transform(X, wavelet='db1', mode='symmetric', **kwargs):\n",
    "        \"\"\"\n",
    "        Single level decomposition (discrete)\n",
    "        \"\"\"\n",
    "        array = np.array(X)\n",
    "        coeffs = pywt.dwt(array, wavelet, mode=mode)\n",
    "        coeffs_torch = [torch.tensor(c) for c in coeffs]\n",
    "        return torch.cat(coeffs_torch, dim=-1)\n",
    "    \n",
    "class CwtTransform:\n",
    "    @staticmethod\n",
    "    def transform(X,wavelet='gaus1',mode='symmetric', **kwargs):\n",
    "        \"\"\"\n",
    "        Single level decomposition (continuous)\n",
    "        \"\"\"\n",
    "        array = np.array(X)\n",
    "        coeffs = pywt.cwt(array, wavelet, mode=mode)\n",
    "        coeffs_torch = [torch.tensor(c) for c in coeffs]\n",
    "        return torch.cat(coeffs_torch, dim=-1)\n",
    "    \n",
    "class AutoRegTransform:\n",
    "    @staticmethod\n",
    "    def get_ar_coefficients(X, k=3, **kwargs):\n",
    "        \"\"\"\n",
    "        Perform an autoregression on each example, the coefficient of the autoregression are used in the representation of the signal.\n",
    "        \n",
    "        k: the number of coefficients computed\n",
    "        \"\"\"\n",
    "        n, p = X.shape\n",
    "        X = np.array(X)\n",
    "        ar_coefficients = np.zeros((n, k))\n",
    "        for i in range(n):\n",
    "            model = AutoReg(X[i], lags=k).fit()\n",
    "            ar_coefficients[i] = model.params[1:k+1]\n",
    "        return ar_coefficients\n",
    "\n",
    "    @staticmethod\n",
    "    def transform(X, k=3, **kwargs):\n",
    "        return AutoRegTransform.get_ar_coefficients(X, k)\n",
    "\n",
    "class ShannonEncodingTransform:\n",
    "    @staticmethod\n",
    "    def transform(X, level=4, wavelet='db1', mode='symmetric', **kwargs):\n",
    "        '''\n",
    "        Inspired by https://fr.mathworks.com/help/wavelet/ug/ecg-classification-using-wavelet-features.html\n",
    "        '''\n",
    "        def compute_shannon_entropy(signal):\n",
    "            return -np.nansum(signal**2 * np.log(signal**2))\n",
    "        \n",
    "        n_examples = X.shape[0]\n",
    "        wp = pywt.WaveletPacket(X[0, :], wavelet=\"sym8\", maxlevel=3)\n",
    "        packet_names = [node.path for node in wp.get_level(3, \"natural\")]\n",
    "        \n",
    "        feature_matrix_wav_packet_entropy = np.full((n_examples, 8), np.nan)\n",
    "        for i in range(len(X)):\n",
    "            wp = pywt.WaveletPacket(X[i, :], wavelet=\"sym8\", maxlevel=3)\n",
    "            for j in range(len(packet_names)):\n",
    "                new_wp = pywt.WaveletPacket(data=None, wavelet=\"sym8\", maxlevel=3)\n",
    "                new_wp[packet_names[j]] = wp[packet_names[j]].data\n",
    "                reconstructed_signal = new_wp.reconstruct(update=False)\n",
    "                feature_matrix_wav_packet_entropy[i, j] = compute_shannon_entropy(reconstructed_signal)\n",
    "        return feature_matrix_wav_packet_entropy\n",
    "\n",
    "class WaveletLeadersTransform:\n",
    "    @staticmethod\n",
    "    def transform(X, j1=2, j2=4, **kwargs):\n",
    "        '''\n",
    "        Inspired by https://fr.mathworks.com/help/wavelet/ug/ecg-classification-using-wavelet-features.html\n",
    "        '''\n",
    "        n = X.shape[0] if X.ndim > 1 else 1\n",
    "        transformed_X = -np.ones((n, 2))\n",
    "        for i in range(X.shape[0]):\n",
    "            dwt, lwt = mfa.mf_analysis_full(\n",
    "                X[i],\n",
    "                scaling_ranges=[(j1, j2)],\n",
    "                q=build_q_log(1, 10, 20),\n",
    "                n_cumul=2,\n",
    "                p_exp=np.inf,\n",
    "                gamint=0.0\n",
    "            )\n",
    "            sf, cumul, mfs, hmin = lwt\n",
    "            transformed_X[i, :] = sf.H.item(), cumul.log_cumulants[1].item()\n",
    "        return transformed_X\n",
    "\n",
    "class MultiFracsTransform:\n",
    "    @staticmethod\n",
    "    def transform(X, j1=2, j2=4, **kwargs):\n",
    "        '''\n",
    "        Use the multifractal framework.\n",
    "        The representation obtained is inspired by HRVMultiScaling_ivanov1999:\n",
    "        [degree of multifractality, tau(3), X[i].std()]\n",
    "        where tau(3) is characterizing the scaling of the third moment Z_3(a).\n",
    "        '''\n",
    "        n = X.shape[0] if X.ndim > 1 else 1\n",
    "        transformed_X = -np.ones((n, 3))\n",
    "        for i in range(X.shape[0]):\n",
    "            dwt, lwt = mfa.mf_analysis_full(\n",
    "                X[i],\n",
    "                scaling_ranges=[(j1, j2)],\n",
    "                q=build_q_log(1, 10, 20),\n",
    "                n_cumul=2,\n",
    "                p_exp=np.inf,\n",
    "                gamint=0.0\n",
    "            )\n",
    "            sf, cumul, mfs, hmin = lwt\n",
    "            tau = interp1d(sf.q, sf.zeta[:,0,0], kind='linear')\n",
    "            degree_of_multifractality = np.max(mfs.hq) - np.min(mfs.hq)\n",
    "            transformed_X[i, :] = degree_of_multifractality, tau(3).item(), X[i].std()\n",
    "        return transformed_X\n",
    "\n",
    "class CrossCorTransform:\n",
    "    @staticmethod\n",
    "    def transform(X, new_dim=10, **kwargs):\n",
    "        \"\"\"\n",
    "        Compute the cross covariance between examples and then do PCA.\n",
    "        \"\"\"\n",
    "        crosscor = np.corrcoef(X)\n",
    "\n",
    "        pca = PCA(n_components=new_dim)\n",
    "        transformed_data = pca.fit_transform(crosscor)\n",
    "        return transformed_data# , pca.components_\n",
    "        \n",
    "        # eigen_values, eigen_vectors = np.linalg.eigh(crosscor)\n",
    "        \n",
    "        # return transformed_X\n",
    "\n",
    "class AutoCorTransform:\n",
    "    @staticmethod\n",
    "    def transform(X, k=4, m=10, **kwargs):\n",
    "        \"\"\"\n",
    "        Weird improvisation, does not work\n",
    "        \"\"\"\n",
    "        \n",
    "        n = X.shape[0] if X.ndim > 1 else 1\n",
    "        transformed_X = list()\n",
    "        for i in range(X.shape[0]):\n",
    "            batches = reshape_to_batches(X[i],m)\n",
    "            \n",
    "            autocor = np.corrcoef(batches)\n",
    "            # print(autocor.shape)\n",
    "            pca = PCA(n_components=k)\n",
    "            transformed_data = pca.fit_transform(autocor)\n",
    "            transformed_X.append(pca.components_.flatten())\n",
    "            \n",
    "        return np.array(transformed_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformationRegistry:\n",
    "    def __init__(self):\n",
    "        self.transformations = {}\n",
    "\n",
    "    def register(self, name, transform_class):\n",
    "        self.transformations[name] = transform_class\n",
    "\n",
    "    def get(self, name):\n",
    "        transform_class = self.transformations.get(name)\n",
    "        if transform_class is None:\n",
    "            raise ValueError(f\"Transformation {name} not recognized.\")\n",
    "        return transform_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransform:\n",
    "    def __init__(self, registry):\n",
    "        self.registry = registry\n",
    "\n",
    "    def apply_transformation(self, X, transformation_names, **kwargs):\n",
    "        if not isinstance(transformation_names, list):\n",
    "            transformation_names = [transformation_names]\n",
    "\n",
    "        transformed_parts = []\n",
    "        for name in transformation_names:\n",
    "            transform_class = self.registry.get(name)\n",
    "            transformed_part = transform_class.transform(X, **kwargs)\n",
    "            transformed_parts.append(transformed_part)\n",
    "\n",
    "        return np.concatenate(transformed_parts, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Initialize the registry\n",
    "    registry = TransformationRegistry()\n",
    "\n",
    "    # Register transformations\n",
    "    registry.register('identity', IdentityTransform)\n",
    "    registry.register('fourier', FourierTransform)\n",
    "    registry.register('low_fourier', LowFourierTransform)\n",
    "    registry.register('low_psd', LowPsdTransform)\n",
    "    registry.register('wavedec', WaveDecTransform)\n",
    "    registry.register('dwt', DwtTransform)\n",
    "    registry.register('autoreg', AutoRegTransform)\n",
    "    registry.register('shannon_encoding', ShannonEncodingTransform)\n",
    "    registry.register('wavelet_leaders', WaveletLeadersTransform)\n",
    "    registry.register('multifracs', MultiFracsTransform)\n",
    "    registry.register('crosscor', CrossCorTransform)\n",
    "    registry.register('autocor', AutoCorTransform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation: identity, Shape: (100, 150)\n",
      "Transformation: fourier, Shape: (100, 150)\n",
      "Transformation: low_fourier, Shape: (100, 77)\n",
      "Transformation: low_psd, Shape: (100, 77)\n",
      "Transformation: wavedec, Shape: (100, 10)\n",
      "Transformation: dwt, Shape: (100, 150)\n",
      "Transformation: autoreg, Shape: (100, 3)\n",
      "Transformation: shannon_encoding, Shape: (100, 8)\n",
      "Transformation: wavelet_leaders, Shape: (100, 2)\n",
      "Transformation: crosscor, Shape: (100, 10)\n",
      "Transformation: autocor, Shape: (100, 60)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Initialize the data transformer\n",
    "    data_transformer = DataTransform(registry)\n",
    "\n",
    "    # Example input data\n",
    "    X = np.random.randn(100, 150)  # Example input data\n",
    "    y = np.random.randint(0, 2, 100)  # Example labels\n",
    "    \n",
    "    for trans_names in registry.transformations.keys():\n",
    "        trans_names_str = [str(name) for name in trans_names]\n",
    "        trans_name_str = '+'.join(trans_names_str) if isinstance(trans_names, list) else trans_names\n",
    "        kwargs = trans_names[1] if isinstance(trans_names, list) and len(trans_names) > 1 else {}\n",
    "        trans_names = trans_names[0] if isinstance(trans_names, list) else trans_names\n",
    "        \n",
    "        # Apply transformation\n",
    "        transformed_X = data_transformer.apply_transformation(X, trans_names, **kwargs)\n",
    "        \n",
    "        print(f\"Transformation: {trans_name_str}, Shape: {transformed_X.shape}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation: identity, Classifier: SVM, Mean Accuracy: 0.470, Std Dev: 0.051\n",
      "Transformation: identity, Classifier: DecisionTree, Mean Accuracy: 0.450, Std Dev: 0.100\n",
      "Transformation: identity, Classifier: RandomForest, Mean Accuracy: 0.550, Std Dev: 0.045\n",
      "Transformation: crosscor, Classifier: SVM, Mean Accuracy: 0.530, Std Dev: 0.121\n",
      "Transformation: crosscor, Classifier: DecisionTree, Mean Accuracy: 0.540, Std Dev: 0.092\n",
      "Transformation: crosscor, Classifier: RandomForest, Mean Accuracy: 0.530, Std Dev: 0.068\n",
      "Transformation: autocor+{'m': 4, 'k': 4}, Classifier: SVM, Mean Accuracy: 0.580, Std Dev: 0.051\n",
      "Transformation: autocor+{'m': 4, 'k': 4}, Classifier: DecisionTree, Mean Accuracy: 0.640, Std Dev: 0.058\n",
      "Transformation: autocor+{'m': 4, 'k': 4}, Classifier: RandomForest, Mean Accuracy: 0.580, Std Dev: 0.040\n",
      "Transformation: fourier, Classifier: SVM, Mean Accuracy: 0.440, Std Dev: 0.073\n",
      "Transformation: fourier, Classifier: DecisionTree, Mean Accuracy: 0.410, Std Dev: 0.116\n",
      "Transformation: fourier, Classifier: RandomForest, Mean Accuracy: 0.410, Std Dev: 0.049\n",
      "Transformation: wavedec, Classifier: SVM, Mean Accuracy: 0.460, Std Dev: 0.097\n",
      "Transformation: wavedec, Classifier: DecisionTree, Mean Accuracy: 0.470, Std Dev: 0.093\n",
      "Transformation: wavedec, Classifier: RandomForest, Mean Accuracy: 0.390, Std Dev: 0.097\n",
      "Transformation: autoreg+{'k': 3}, Classifier: SVM, Mean Accuracy: 0.610, Std Dev: 0.058\n",
      "Transformation: autoreg+{'k': 3}, Classifier: DecisionTree, Mean Accuracy: 0.540, Std Dev: 0.073\n",
      "Transformation: autoreg+{'k': 3}, Classifier: RandomForest, Mean Accuracy: 0.550, Std Dev: 0.095\n",
      "Transformation: identity, Classifier: SVM, Mean Accuracy: 0.470, Std Dev: 0.051\n",
      "Transformation: identity, Classifier: DecisionTree, Mean Accuracy: 0.450, Std Dev: 0.100\n",
      "Transformation: identity, Classifier: RandomForest, Mean Accuracy: 0.550, Std Dev: 0.045\n",
      "Transformation: crosscor, Classifier: SVM, Mean Accuracy: 0.530, Std Dev: 0.121\n",
      "Transformation: crosscor, Classifier: DecisionTree, Mean Accuracy: 0.540, Std Dev: 0.092\n",
      "Transformation: crosscor, Classifier: RandomForest, Mean Accuracy: 0.530, Std Dev: 0.068\n",
      "Transformation: autocor+{'m': 4, 'k': 4}, Classifier: SVM, Mean Accuracy: 0.580, Std Dev: 0.051\n",
      "Transformation: autocor+{'m': 4, 'k': 4}, Classifier: DecisionTree, Mean Accuracy: 0.640, Std Dev: 0.058\n",
      "Transformation: autocor+{'m': 4, 'k': 4}, Classifier: RandomForest, Mean Accuracy: 0.580, Std Dev: 0.040\n",
      "Transformation: fourier, Classifier: SVM, Mean Accuracy: 0.440, Std Dev: 0.073\n",
      "Transformation: fourier, Classifier: DecisionTree, Mean Accuracy: 0.410, Std Dev: 0.116\n",
      "Transformation: fourier, Classifier: RandomForest, Mean Accuracy: 0.410, Std Dev: 0.049\n",
      "Transformation: wavedec, Classifier: SVM, Mean Accuracy: 0.460, Std Dev: 0.097\n",
      "Transformation: wavedec, Classifier: DecisionTree, Mean Accuracy: 0.470, Std Dev: 0.093\n",
      "Transformation: wavedec, Classifier: RandomForest, Mean Accuracy: 0.390, Std Dev: 0.097\n",
      "Transformation: autoreg+{'k': 3}, Classifier: SVM, Mean Accuracy: 0.610, Std Dev: 0.058\n",
      "Transformation: autoreg+{'k': 3}, Classifier: DecisionTree, Mean Accuracy: 0.540, Std Dev: 0.073\n",
      "Transformation: autoreg+{'k': 3}, Classifier: RandomForest, Mean Accuracy: 0.550, Std Dev: 0.095\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    \n",
    "\n",
    "    # Define the classifiers to be tested\n",
    "    classifiers = {\n",
    "        'SVM': SVC(),\n",
    "        'DecisionTree': DecisionTreeClassifier(),\n",
    "        'RandomForest': RandomForestClassifier()\n",
    "    }\n",
    "\n",
    "    # Define the transformations to be tested\n",
    "    transformations = [\n",
    "        ['identity'],\n",
    "        ['crosscor'],\n",
    "        ['autocor',{'m':4,'k':4}],\n",
    "        ['fourier'],\n",
    "        ['wavedec'],\n",
    "        ['autoreg', {'k': 3}]\n",
    "    ]\n",
    "\n",
    "    \n",
    "\n",
    "    # Function to evaluate a classifier using cross-validation\n",
    "    def evaluate_classifier_cv(classifier, X, y):\n",
    "        scores = cross_val_score(classifier, X, y, cv=5)  # 5-fold cross-validation\n",
    "        return np.mean(scores), np.std(scores)\n",
    "\n",
    "    # Loop over each transformation and each classifier\n",
    "    results = {}\n",
    "\n",
    "    for trans_names in transformations:\n",
    "        trans_names_str = [str(name) for name in trans_names]\n",
    "        trans_name_str = '+'.join(trans_names_str) if isinstance(trans_names, list) else trans_names\n",
    "        kwargs = trans_names[1] if isinstance(trans_names, list) and len(trans_names) > 1 else {}\n",
    "        trans_names = trans_names[0] if isinstance(trans_names, list) else trans_names\n",
    "        \n",
    "        # Apply transformation\n",
    "        transformed_X = data_transformer.apply_transformation(X, trans_names, **kwargs)\n",
    "        \n",
    "        # Standardize the data (important for some classifiers like SVM)\n",
    "        scaler = StandardScaler()\n",
    "        transformed_X = scaler.fit_transform(transformed_X)\n",
    "        \n",
    "        results[trans_name_str] = {}\n",
    "        for clf_name, clf in classifiers.items():\n",
    "            # Evaluate the classifier with cross-validation\n",
    "            mean_accuracy, std_accuracy = evaluate_classifier_cv(clf, transformed_X, y)\n",
    "            results[trans_name_str][clf_name] = (mean_accuracy, std_accuracy)\n",
    "            print(f\"Transformation: {trans_name_str}, Classifier: {clf_name}, Mean Accuracy: {mean_accuracy:.3f}, Std Dev: {std_accuracy:.3f}\")\n",
    "\n",
    "    # Print the results\n",
    "    for trans_name, clf_results in results.items():\n",
    "        for clf_name, (mean_accuracy, std_accuracy) in clf_results.items():\n",
    "            print(f\"Transformation: {trans_name}, Classifier: {clf_name}, Mean Accuracy: {mean_accuracy:.3f}, Std Dev: {std_accuracy:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
