{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representation\n",
    "- Multifractal analysis (1ere approche)\n",
    "\n",
    "- Discrete Fourier Transform (DFT) $\\checkmark$\n",
    "- Spectrogram\n",
    "- Autoregression $\\checkmark$\n",
    "- Shannon encoding $\\checkmark$\n",
    "- Wavelets (en cours)\n",
    "\n",
    "- Local symbolic features\n",
    "- SAX representation\n",
    "- Approximate entropy\n",
    "\n",
    "ML\n",
    "\n",
    "- Autoencoder\n",
    "\n",
    "- RNN\n",
    "- LSTM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/kymatio/kymatio.git\n",
    "# %pip install -e kymatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pywt\n",
    "from statsmodels.tsa.ar_model import AutoReg, ar_select_order\n",
    "import pymultifracs.mfa as mfa\n",
    "from pymultifracs.utils import build_q_log\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kymatio import Scattering1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_to_batches(array, m):\n",
    "    \"\"\"\n",
    "    Transform an array of shape (n, p) into a list of arrays of shape (m, p).\n",
    "    \"\"\"\n",
    "    array = np.asarray(array)\n",
    "    p = array.shape[-1]\n",
    "    num_batches = p // m\n",
    "    return [array[i * m:(i + 1) * m] for i in range(num_batches)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=32):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim,128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, hidden_dim),\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, input_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "    def fit(self,X):\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        n_batch = 32\n",
    "        # Create a DataLoader for the dataset\n",
    "        X_tensor = torch.FloatTensor(X)\n",
    "        dataset = TensorDataset(X_tensor, X_tensor)\n",
    "        dataloader = DataLoader(dataset, batch_size=256, shuffle=True)\n",
    "        # Train the autoencoder\n",
    "        num_epochs = 50\n",
    "        for epoch in range(num_epochs):\n",
    "            for data in dataloader:\n",
    "                inputs, _ = data\n",
    "                inputs = inputs #.to(device)\n",
    "                outputs = self(inputs)\n",
    "                loss = criterion(outputs, inputs)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentityTransform:\n",
    "    @staticmethod\n",
    "    def transform(X, **kwargs):\n",
    "        return X\n",
    "\n",
    "class Mean:\n",
    "    @staticmethod\n",
    "    def transform(X,**kwargs):\n",
    "        return np.expand_dims(X.mean(axis=-1),axis=-1)\n",
    "    \n",
    "class StandardDeviation:\n",
    "    @staticmethod\n",
    "    def transform(X,**kwargs):\n",
    "        return np.expand_dims(X.std(axis=-1),axis=-1)\n",
    "class FourierTransform:\n",
    "    @staticmethod\n",
    "    def transform(X, new_dimension=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Return the fourier transform of size 'new_dimension'.\n",
    "        \"\"\"\n",
    "        fourier_transform = np.fft.fft(X, n=new_dimension,axis=-1)\n",
    "        modulus = np.abs(fourier_transform)\n",
    "        return modulus\n",
    "\n",
    "class LowFourierTransform:\n",
    "    @staticmethod\n",
    "    def transform(X, fs=250, cutoff_min=.3, cutoff_max = 4.5, n=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Fourier transform with a cutoff_ratio.\n",
    "\n",
    "        fs: sampling frequency\n",
    "        [cutoff_min, cutoff_max]: frequency interval that we consider\n",
    "        n: new_dimension before cutoff\n",
    "\n",
    "        Return the cutoff fourier transform.\n",
    "        \"\"\"\n",
    "        fourier_transform = np.fft.fft(X,n=n,axis=-1)\n",
    "        if n is None:\n",
    "            n = X.shape[1]\n",
    "        frequencies = np.fft.fftfreq(n, d=1/fs)\n",
    "        mask = (cutoff_min < frequencies) & (frequencies < cutoff_max)\n",
    "        fourier_transform = fourier_transform[:, mask]\n",
    "        modulus = np.abs(fourier_transform)\n",
    "        return modulus\n",
    "\n",
    "class LowPsdTransform:\n",
    "    @staticmethod\n",
    "    def transform(X, fs=250, cutoff_min=.3, cutoff_max = 4.5, n=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Power Spectrum Density with a cutoff_ratio.\n",
    "\n",
    "        fs: sampling frequency\n",
    "        [cutoff_min, cutoff_max]: frequency interval that we consider\n",
    "        n: new_dimension before cutoff\n",
    "\n",
    "        Return the cutoff power spectrum density (the fourier transform of the autocorrelation).\n",
    "        \"\"\"\n",
    "        fourier_transform = np.fft.fft(X, n=n, axis=-1)\n",
    "        if n is None:\n",
    "            n = X.shape[1]\n",
    "        frequencies = np.fft.fftfreq(n, d=1/fs)\n",
    "        mask = (cutoff_min < frequencies) & (frequencies < cutoff_max)\n",
    "        fourier_transform = fourier_transform[:, mask]\n",
    "        psd = fourier_transform * np.conj(fourier_transform)\n",
    "        return psd.real\n",
    "\n",
    "class WaveDecTransform:\n",
    "    @staticmethod\n",
    "    def transform(X, level=4, wavelet='db1', mode='symmetric', **kwargs):\n",
    "        \"\"\"\n",
    "        Multilevel decomposition\n",
    "        \"\"\"\n",
    "        array = np.array(X)\n",
    "        coeffs = pywt.wavedec(array, wavelet, mode=mode, level=level)\n",
    "        coeffs_torch = [torch.tensor(c) for c in coeffs[:1]]\n",
    "        return torch.cat(coeffs_torch, dim=-1)\n",
    "\n",
    "class DwtTransform:\n",
    "    @staticmethod\n",
    "    def transform(X, wavelet='db1', mode='symmetric', **kwargs):\n",
    "        \"\"\"\n",
    "        Single level decomposition (discrete)\n",
    "        \"\"\"\n",
    "        array = np.array(X)\n",
    "        coeffs = pywt.dwt(array, wavelet, mode=mode)\n",
    "        coeffs_torch = [torch.tensor(c) for c in coeffs[:1]]\n",
    "        return torch.cat(coeffs_torch, dim=-1)\n",
    "    \n",
    "class CwtTransform:\n",
    "    @staticmethod\n",
    "    def transform(X, scales = np.arange(1,100,20), wavelet='gaus1', pca_components = 10, **kwargs):\n",
    "        \"\"\"\n",
    "        Continuous Wavelet Transform followed by PCA\n",
    "        \"\"\"\n",
    "        array = np.array(X)\n",
    "        coeffs, freqs = pywt.cwt(array,scales= scales, wavelet=wavelet)\n",
    "        \n",
    "        coeffs = np.transpose(coeffs,(1,0,2) )\n",
    "        \n",
    "        mean_coefs = np.mean(np.abs(coeffs), axis=1)\n",
    "        std_coefs = np.std(np.abs(coeffs), axis=1)\n",
    "        features = np.concatenate((mean_coefs, std_coefs),axis=-1)\n",
    "        \n",
    "        pca = PCA(n_components=pca_components) \n",
    "        X_pca = pca.fit_transform(features)\n",
    "        return X_pca\n",
    "    \n",
    "class AutoRegTransform:\n",
    "    @staticmethod\n",
    "    def get_ar_coefficients(X, k=3, **kwargs):\n",
    "        \"\"\"\n",
    "        Perform an autoregression on each example, the coefficient of the autoregression are used in the representation of the signal.\n",
    "        \n",
    "        k: the number of coefficients computed\n",
    "        \"\"\"\n",
    "        n, p = X.shape\n",
    "        X = np.array(X)\n",
    "        ar_coefficients = np.zeros((n, k))\n",
    "        for i in range(n):\n",
    "            model = AutoReg(X[i], lags=k).fit()\n",
    "            ar_coefficients[i] = model.params[1:k+1]\n",
    "        return ar_coefficients\n",
    "\n",
    "    @staticmethod\n",
    "    def transform(X, k=3, **kwargs):\n",
    "        return AutoRegTransform.get_ar_coefficients(X, k)\n",
    "\n",
    "class ShannonEncodingTransform:\n",
    "    @staticmethod\n",
    "    def transform(X, level=4, wavelet='db1', mode='symmetric', **kwargs):\n",
    "        '''\n",
    "        Inspired by https://fr.mathworks.com/help/wavelet/ug/ecg-classification-using-wavelet-features.html\n",
    "\n",
    "        -> ECG Classification Using Wavelet Packet Entropy and Random Forests (https://www.mdpi.com/1099-4300/18/8/285)\n",
    "\n",
    "        '''\n",
    "        def compute_shannon_entropy(signal):\n",
    "            return -np.nansum(signal**2 * np.log(signal**2))\n",
    "        \n",
    "        n_examples = X.shape[0]\n",
    "        wp = pywt.WaveletPacket(X[0, :], wavelet=\"sym8\", maxlevel=3)\n",
    "        packet_names = [node.path for node in wp.get_level(3, \"natural\")]\n",
    "        \n",
    "        feature_matrix_wav_packet_entropy = np.full((n_examples, 8), np.nan)\n",
    "        for i in range(len(X)):\n",
    "            wp = pywt.WaveletPacket(X[i, :], wavelet=\"sym8\", maxlevel=3)\n",
    "            for j in range(len(packet_names)):\n",
    "                new_wp = pywt.WaveletPacket(data=None, wavelet=\"sym8\", maxlevel=3)\n",
    "                new_wp[packet_names[j]] = wp[packet_names[j]].data\n",
    "                reconstructed_signal = new_wp.reconstruct(update=False)\n",
    "                feature_matrix_wav_packet_entropy[i, j] = compute_shannon_entropy(reconstructed_signal)\n",
    "        return feature_matrix_wav_packet_entropy\n",
    "\n",
    "class WaveletLeadersTransform:\n",
    "    @staticmethod\n",
    "    def transform(X, j1=2, j2=4, **kwargs):\n",
    "        '''\n",
    "        Use the multifractal framework.\n",
    "        The representation obtained is inspired by https://fr.mathworks.com/help/wavelet/ug/ecg-classification-using-wavelet-features.html:\n",
    "        [ width of the singularity spectrum = degree of multifractality, log_cumulants[1]]\n",
    "        \n",
    "        '''\n",
    "        n = X.shape[0] if X.ndim > 1 else 1\n",
    "        transformed_X = -np.ones((n, 2))\n",
    "        for i in range(X.shape[0]):\n",
    "            # print(i)\n",
    "            dwt, lwt = mfa.mf_analysis_full(\n",
    "                X[i],\n",
    "                scaling_ranges=[(j1, j2)],\n",
    "                q=build_q_log(1, 10, 20),\n",
    "                n_cumul=2,\n",
    "                p_exp=np.inf,\n",
    "                gamint=0.0\n",
    "            )\n",
    "            sf, cumul, mfs, hmin = lwt\n",
    "            transformed_X[i, :] = np.max(mfs.hq) - np.min(mfs.hq), cumul.log_cumulants[1].item()\n",
    "        return transformed_X\n",
    "\n",
    "class MultiFracsTransform:\n",
    "    @staticmethod\n",
    "    def transform(X, j1=2, j2=4, **kwargs):\n",
    "        '''\n",
    "        Use the multifractal framework.\n",
    "        The representation obtained is inspired by HRVMultiScaling_ivanov1999:\n",
    "        [degree of multifractality, tau(3), X[i].std()]\n",
    "        where tau(3) is characterizing the scaling of the third moment Z_3(a).\n",
    "        '''\n",
    "        n = X.shape[0] if X.ndim > 1 else 1\n",
    "        transformed_X = -np.ones((n, 3))\n",
    "        for i in range(X.shape[0]):\n",
    "            dwt, lwt = mfa.mf_analysis_full(\n",
    "                X[i],\n",
    "                scaling_ranges=[(j1, j2)],\n",
    "                q=build_q_log(1, 10, 20),\n",
    "                n_cumul=2,\n",
    "                p_exp=np.inf,\n",
    "                gamint=0.0\n",
    "            )\n",
    "            sf, cumul, mfs, hmin = lwt\n",
    "            tau = interp1d(sf.q, sf.zeta[:,0,0], kind='linear')\n",
    "            degree_of_multifractality = np.max(mfs.hq) - np.min(mfs.hq)\n",
    "            transformed_X[i, :] = degree_of_multifractality, tau(3).item(), X[i].std()\n",
    "        return transformed_X\n",
    "    \n",
    "class NewMultiFracsTransform:\n",
    "    @staticmethod\n",
    "    def transform(X, j1=2, j2=4, **kwargs):\n",
    "        '''\n",
    "        Use the multifractal framework.\n",
    "        The representation obtained is inspired by HRVMultiScaling_ivanov1999:\n",
    "        [degree of multifractality, tau(3), X[i].std()]\n",
    "        where tau(3) is characterizing the scaling of the third moment Z_3(a).\n",
    "        '''\n",
    "        n = X.shape[0] if X.ndim > 1 else 1\n",
    "        transformed_X = -np.ones((n, 5))\n",
    "        for i in range(X.shape[0]):\n",
    "            dwt, lwt = mfa.mf_analysis_full(\n",
    "                X[i],\n",
    "                scaling_ranges=[(j1, j2)],\n",
    "                q=build_q_log(1, 10, 20),\n",
    "                n_cumul=2,\n",
    "                p_exp=np.inf,\n",
    "                gamint=0.0\n",
    "            )\n",
    "            sf, cumul, mfs, hmin = lwt\n",
    "            tau = interp1d(sf.q, sf.zeta[:,0,0], kind='linear')\n",
    "            degree_of_multifractality = np.max(mfs.hq) - np.min(mfs.hq)\n",
    "            # print(sf.H.item())\n",
    "            transformed_X[i, :] = degree_of_multifractality, sf.H.item(), tau(2).item(), tau(3).item(), X[i].std()\n",
    "        return transformed_X\n",
    "\n",
    "class CrossCorTransform:\n",
    "    @staticmethod\n",
    "    def transform(X, new_dim=10, **kwargs):\n",
    "        \"\"\"\n",
    "        Compute the cross covariance between examples and then do PCA.\n",
    "        \"\"\"\n",
    "        crosscor = np.corrcoef(X)\n",
    "\n",
    "        pca = PCA(n_components=new_dim)\n",
    "        transformed_data = pca.fit_transform(crosscor)\n",
    "        return transformed_data# , pca.components_\n",
    "        \n",
    "        # eigen_values, eigen_vectors = np.linalg.eigh(crosscor)\n",
    "        \n",
    "        # return transformed_X\n",
    "\n",
    "class AutoCorTransform:\n",
    "    @staticmethod\n",
    "    def transform(X, k=4, m=10, **kwargs):\n",
    "        \"\"\"\n",
    "        Weird improvisation, does not work\n",
    "        \"\"\"\n",
    "        \n",
    "        n = X.shape[0] if X.ndim > 1 else 1\n",
    "        transformed_X = list()\n",
    "        for i in range(X.shape[0]):\n",
    "            batches = reshape_to_batches(X[i],m)\n",
    "            \n",
    "            autocor = np.corrcoef(batches)\n",
    "            # print(autocor.shape)\n",
    "            pca = PCA(n_components=k)\n",
    "            transformed_data = pca.fit_transform(autocor)\n",
    "            transformed_X.append(pca.components_.flatten())\n",
    "            \n",
    "        return np.array(transformed_X)\n",
    "    \n",
    "class AutoEncoderTransform:\n",
    "    @staticmethod\n",
    "    def transform(X, mode = 'n-pretrained', fourier_transform = True, n_fourier = 128, dim_encoder = 16, **kwargs):\n",
    "        \"\"\"\n",
    "        AutoEncoder Transform\n",
    "        \"\"\"\n",
    "        n = 200\n",
    "        if mode == 'pretrained':\n",
    "            fX = torch.fft.fft(torch.FloatTensor(X),n = n)\n",
    "            X = (fX  * torch.conj(fX)).real\n",
    "            autoencoder = AutoEncoder(n,10)\n",
    "            autoencoder.load_state_dict(torch.load('autoencoder_state_dict.pth'))\n",
    "            autoencoder.eval()  # Set the model to evaluation mode\n",
    "            return autoencoder.encoder(X).detach().numpy()\n",
    "        \n",
    "        else:\n",
    "            if fourier_transform:# PSD  \n",
    "                fX = torch.fft.fft(torch.FloatTensor(X), n=n_fourier)\n",
    "                X = (fX  * torch.conj(fX)).real\n",
    "            X = torch.FloatTensor(X)\n",
    "            n = X.shape[-1]\n",
    "            autoencoder = AutoEncoder(n,dim_encoder)\n",
    "            autoencoder.fit(X)\n",
    "            autoencoder.eval()  # Set the model to evaluation mode\n",
    "            return autoencoder.encoder(X).detach().numpy()\n",
    "    \n",
    "class WaveletScattering:\n",
    "    @staticmethod\n",
    "    def transform(X, J=4, Q=(8,1), pca_components = 0):\n",
    "        \"\"\"\n",
    "        The parameter J specifies the maximum scale of the low-pass filters as a power of two.\n",
    "        In other words, the largest filter will be concentrated in a time interval of size 2**J\n",
    "\n",
    "        \"\"\"\n",
    "        T = X.shape[-1]\n",
    "        scattering = Scattering1D(J, T, Q)\n",
    "        Sx = scattering(X)\n",
    "        # print('Sx1.shape',Sx.shape)\n",
    "        n,m, p = Sx.shape\n",
    "        Sx = Sx.reshape((n,m*p))\n",
    "        # print('Sx2.shape',Sx.shape)\n",
    "        if pca_components > 0:\n",
    "            pca = PCA(n_components=pca_components)\n",
    "            transformed_data = pca.fit_transform(Sx)\n",
    "            return transformed_data\n",
    "        else:\n",
    "            return Sx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformationRegistry:\n",
    "    def __init__(self):\n",
    "        self.transformations = {}\n",
    "\n",
    "    def register(self, name, transform_class):\n",
    "        self.transformations[name] = transform_class\n",
    "\n",
    "    def get(self, name):\n",
    "        transform_class = self.transformations.get(name)\n",
    "        if transform_class is None:\n",
    "            raise ValueError(f\"Transformation {name} not recognized.\")\n",
    "        return transform_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransform:\n",
    "    def __init__(self, registry, save_data = True,verbose = True):\n",
    "        self.registry = registry\n",
    "\n",
    "        self.save_data = save_data\n",
    "        self.data = {}\n",
    "\n",
    "    @staticmethod\n",
    "    def handle_trans_kwargs(input):\n",
    "        '''\n",
    "        input: [str, dict] or [str] or str\n",
    "        Return: str, dict or str, {}\n",
    "        '''\n",
    "        if isinstance(input, list):\n",
    "            if len(input) == 2 and isinstance(input[0], str) and isinstance(input[1], dict):\n",
    "                return input[0], input[1]\n",
    "            elif len(input) == 1 and isinstance(input[0], str):\n",
    "                return input[0], {}\n",
    "            else:\n",
    "                raise ValueError(\"Invalid list input. Expected [str, dict] or [str].\")\n",
    "        elif isinstance(input, str):\n",
    "            return input, {}\n",
    "        else:\n",
    "            raise ValueError(\"Invalid input type. Expected [str, dict], [str], or str.\")\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_trans_kwargs_str(trans_name, kwargs):\n",
    "        def str_dict(dictionnary):\n",
    "            res = ''\n",
    "            for key,value in dictionnary.items():\n",
    "                res+=f'{key}={value}_'\n",
    "            return res\n",
    "        return (trans_name + '_' + str_dict(kwargs) )[:-1]\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_full_trans_kwargs_str(transformation):\n",
    "        # print(transformation)\n",
    "        res =''\n",
    "        transformation = DataTransform.sanitize_transformations(transformation)\n",
    "        for trans in transformation:\n",
    "            res += DataTransform.get_trans_kwargs_str(*DataTransform.handle_trans_kwargs(trans))+'_'\n",
    "        \n",
    "        return res[:-1]\n",
    "    \n",
    "    @staticmethod\n",
    "    def sanitize_transformations(transformations):\n",
    "        if isinstance(transformations, str):\n",
    "            sanitized_transformations = [[transformations]]\n",
    "        elif isinstance(transformations, list) and len(transformations) == 2 and isinstance(transformations[0], str) and isinstance(transformations[1], dict):\n",
    "            sanitized_transformations = [transformations]\n",
    "\n",
    "        elif isinstance(transformations, list):\n",
    "            sanitized_transformations = []\n",
    "            for item in transformations:\n",
    "                if isinstance(item, str):\n",
    "                    sanitized_transformations.append([item])\n",
    "                elif isinstance(item, list) and len(item) == 2 and isinstance(item[0], str) and isinstance(item[1], dict):\n",
    "                    sanitized_transformations.append(item)\n",
    "                elif isinstance(item, list) and len(item) == 1 and isinstance(item[0], str):\n",
    "                    sanitized_transformations.append(item)\n",
    "                else:\n",
    "                    raise ValueError(\"Invalid list input. Expected [str, dict] or [str].\")\n",
    "        return sanitized_transformations\n",
    "    \n",
    "    def apply_transformation(self, X, transformations):      #, **kwargs):\n",
    "        '''\n",
    "        X: data\n",
    "        transformations: [str, [str, dict], [str], ...] or [str] or str\n",
    "        '''\n",
    "        \n",
    "        sanitized_transformations = DataTransform.sanitize_transformations(transformations)\n",
    "        transformed_parts = []\n",
    "        for transformation in sanitized_transformations:\n",
    "            trans_name, kwargs = DataTransform.handle_trans_kwargs(transformation)\n",
    "            trans_name_kwargs = DataTransform.get_trans_kwargs_str(trans_name, kwargs)\n",
    "\n",
    "            if self.save_data and (trans_name_kwargs in self.data.keys()):\n",
    "                transformed_parts.append(self.data[trans_name_kwargs])\n",
    "            else:\n",
    "                transform_class = self.registry.get(trans_name)\n",
    "                print(f'Computing  {trans_name_kwargs} ...', end='', flush=True)\n",
    "                transformed_part = transform_class.transform(X, **kwargs)\n",
    "                print('\\r' + ' ' * len(f'Computing  {trans_name} ...') + '\\r', end='')\n",
    "                self.data[trans_name_kwargs] = transformed_part\n",
    "                transformed_parts.append(transformed_part)\n",
    "\n",
    "        return np.concatenate(transformed_parts, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_registry():\n",
    "    registry = TransformationRegistry()\n",
    "\n",
    "    # Register transformations\n",
    "    registry.register('identity', IdentityTransform)\n",
    "    registry.register('mean', Mean)\n",
    "    registry.register('std', StandardDeviation)\n",
    "    registry.register('fourier', FourierTransform)\n",
    "    registry.register('low_fourier', LowFourierTransform)\n",
    "    registry.register('low_psd', LowPsdTransform)\n",
    "    registry.register('wavedec', WaveDecTransform)\n",
    "    registry.register('dwt', DwtTransform)\n",
    "    registry.register('cwt', CwtTransform)\n",
    "    registry.register('autoreg', AutoRegTransform)\n",
    "    registry.register('shannon_encoding', ShannonEncodingTransform)\n",
    "    registry.register('wavelet_leaders', WaveletLeadersTransform)\n",
    "    registry.register('multifracs', MultiFracsTransform)\n",
    "    registry.register('newmultifracs', NewMultiFracsTransform)\n",
    "    registry.register('crosscor', CrossCorTransform)\n",
    "    registry.register('autocor', AutoCorTransform)\n",
    "    registry.register('autoencoder', AutoEncoderTransform)\n",
    "    registry.register('waveletscattering', WaveletScattering)\n",
    "\n",
    "    return registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Initialize the registry\n",
    "    registry = initialize_registry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation: identity, Shape: (100, 150)\n",
      "Transformation: mean, Shape: (100, 1)\n",
      "Transformation: std, Shape: (100, 1)\n",
      "Transformation: fourier, Shape: (100, 150)\n",
      "Transformation: low_fourier, Shape: (100, 2)\n",
      "Transformation: low_psd, Shape: (100, 2)\n",
      "Transformation: wavedec, Shape: (100, 10)\n",
      "Transformation: dwt, Shape: (100, 75)\n",
      "Transformation: cwt, Shape: (100, 10)\n",
      "Transformation: autoreg, Shape: (100, 3)\n",
      "Transformation: shannon_encoding, Shape: (100, 8)\n",
      "Transformation: wavelet_leaders, Shape: (100, 2)\n",
      "Transformation: multifracs, Shape: (100, 3)\n",
      "Transformation: newmultifracs, Shape: (100, 5)\n",
      "Transformation: crosscor, Shape: (100, 10)\n",
      "Transformation: autocor, Shape: (100, 60)\n",
      "Transformation: autoencoder, Shape: (100, 16)\n",
      "Transformation: waveletscattering, Shape: (100, 450)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Initialize the data transformer\n",
    "    data_transformer = DataTransform(registry)\n",
    "\n",
    "    # Example input data\n",
    "    X = np.random.randn(100, 150)  # Example input data\n",
    "    y = np.random.randint(0, 2, 100)  # Example labels\n",
    "    \n",
    "    for trans_names in registry.transformations.keys():\n",
    "        trans_names_str = [str(name) for name in trans_names]\n",
    "        trans_name_str = '+'.join(trans_names_str) if isinstance(trans_names, list) else trans_names\n",
    "        kwargs = trans_names[1] if isinstance(trans_names, list) and len(trans_names) > 1 else {}\n",
    "        trans_names = trans_names[0] if isinstance(trans_names, list) else trans_names\n",
    "        \n",
    "        # Apply transformation\n",
    "        transformed_X = data_transformer.apply_transformation(X, trans_names, **kwargs)\n",
    "        \n",
    "        print(f\"Transformation: {trans_name_str}, Shape: {transformed_X.shape}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation: identity, Classifier: SVM, Mean Accuracy: 0.500, Std Dev: 0.032\n",
      "Transformation: identity, Classifier: DecisionTree, Mean Accuracy: 0.500, Std Dev: 0.105\n",
      "Transformation: identity, Classifier: RandomForest, Mean Accuracy: 0.430, Std Dev: 0.068\n",
      "Transformation: crosscor, Classifier: SVM, Mean Accuracy: 0.560, Std Dev: 0.092\n",
      "Transformation: crosscor, Classifier: DecisionTree, Mean Accuracy: 0.460, Std Dev: 0.058\n",
      "Transformation: crosscor, Classifier: RandomForest, Mean Accuracy: 0.530, Std Dev: 0.068\n",
      "Transformation: autocor_m=4_k=4, Classifier: SVM, Mean Accuracy: 0.520, Std Dev: 0.024\n",
      "Transformation: autocor_m=4_k=4, Classifier: DecisionTree, Mean Accuracy: 0.500, Std Dev: 0.032\n",
      "Transformation: autocor_m=4_k=4, Classifier: RandomForest, Mean Accuracy: 0.460, Std Dev: 0.097\n",
      "Transformation: fourier_crosscor, Classifier: SVM, Mean Accuracy: 0.490, Std Dev: 0.086\n",
      "Transformation: fourier_crosscor, Classifier: DecisionTree, Mean Accuracy: 0.480, Std Dev: 0.108\n",
      "Transformation: fourier_crosscor, Classifier: RandomForest, Mean Accuracy: 0.500, Std Dev: 0.114\n",
      "Transformation: wavedec, Classifier: SVM, Mean Accuracy: 0.520, Std Dev: 0.140\n",
      "Transformation: wavedec, Classifier: DecisionTree, Mean Accuracy: 0.530, Std Dev: 0.051\n",
      "Transformation: wavedec, Classifier: RandomForest, Mean Accuracy: 0.450, Std Dev: 0.110\n",
      "Transformation: autoreg_k=3, Classifier: SVM, Mean Accuracy: 0.520, Std Dev: 0.081\n",
      "Transformation: autoreg_k=3, Classifier: DecisionTree, Mean Accuracy: 0.480, Std Dev: 0.024\n",
      "Transformation: autoreg_k=3, Classifier: RandomForest, Mean Accuracy: 0.460, Std Dev: 0.086\n",
      "Transformation: identity, Classifier: SVM, Mean Accuracy: 0.500, Std Dev: 0.032\n",
      "Transformation: identity, Classifier: DecisionTree, Mean Accuracy: 0.500, Std Dev: 0.105\n",
      "Transformation: identity, Classifier: RandomForest, Mean Accuracy: 0.430, Std Dev: 0.068\n",
      "Transformation: crosscor, Classifier: SVM, Mean Accuracy: 0.560, Std Dev: 0.092\n",
      "Transformation: crosscor, Classifier: DecisionTree, Mean Accuracy: 0.460, Std Dev: 0.058\n",
      "Transformation: crosscor, Classifier: RandomForest, Mean Accuracy: 0.530, Std Dev: 0.068\n",
      "Transformation: autocor_m=4_k=4, Classifier: SVM, Mean Accuracy: 0.520, Std Dev: 0.024\n",
      "Transformation: autocor_m=4_k=4, Classifier: DecisionTree, Mean Accuracy: 0.500, Std Dev: 0.032\n",
      "Transformation: autocor_m=4_k=4, Classifier: RandomForest, Mean Accuracy: 0.460, Std Dev: 0.097\n",
      "Transformation: fourier_crosscor, Classifier: SVM, Mean Accuracy: 0.490, Std Dev: 0.086\n",
      "Transformation: fourier_crosscor, Classifier: DecisionTree, Mean Accuracy: 0.480, Std Dev: 0.108\n",
      "Transformation: fourier_crosscor, Classifier: RandomForest, Mean Accuracy: 0.500, Std Dev: 0.114\n",
      "Transformation: wavedec, Classifier: SVM, Mean Accuracy: 0.520, Std Dev: 0.140\n",
      "Transformation: wavedec, Classifier: DecisionTree, Mean Accuracy: 0.530, Std Dev: 0.051\n",
      "Transformation: wavedec, Classifier: RandomForest, Mean Accuracy: 0.450, Std Dev: 0.110\n",
      "Transformation: autoreg_k=3, Classifier: SVM, Mean Accuracy: 0.520, Std Dev: 0.081\n",
      "Transformation: autoreg_k=3, Classifier: DecisionTree, Mean Accuracy: 0.480, Std Dev: 0.024\n",
      "Transformation: autoreg_k=3, Classifier: RandomForest, Mean Accuracy: 0.460, Std Dev: 0.086\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    \n",
    "\n",
    "    # Define the classifiers to be tested\n",
    "    classifiers = {\n",
    "        'SVM': SVC(),\n",
    "        'DecisionTree': DecisionTreeClassifier(),\n",
    "        'RandomForest': RandomForestClassifier()\n",
    "    }\n",
    "\n",
    "    # Define the transformations to be tested\n",
    "    transformations = [\n",
    "        'identity',\n",
    "        ['crosscor'],\n",
    "        ['autocor',{'m':4,'k':4}],\n",
    "        [['fourier'],['crosscor']],\n",
    "        ['wavedec'],\n",
    "        ['autoreg', {'k': 3}]\n",
    "    ]\n",
    "\n",
    "    \n",
    "\n",
    "    # Function to evaluate a classifier using cross-validation\n",
    "    def evaluate_classifier_cv(classifier, X, y):\n",
    "        scores = cross_val_score(classifier, X, y, cv=5)  # 5-fold cross-validation\n",
    "        return np.mean(scores), np.std(scores)\n",
    "\n",
    "    # Loop over each transformation and each classifier\n",
    "    results = {}\n",
    "\n",
    "    for trans in transformations:\n",
    "\n",
    "        trans_name_str = DataTransform.get_full_trans_kwargs_str(trans)\n",
    "        # trans_name_str = '+'.join(trans_names_str) if isinstance(trans_names, list) else trans_names\n",
    "        # kwargs = trans_names[1] if isinstance(trans_names, list) and len(trans_names) > 1 else {}\n",
    "        # trans_names = trans_names[0] if isinstance(trans_names, list) else trans_names\n",
    "        \n",
    "        # Apply transformation\n",
    "        # print(trans)\n",
    "        transformed_X = data_transformer.apply_transformation(X, trans)\n",
    "        # Standardize the data (important for some classifiers like SVM)\n",
    "        scaler = StandardScaler()\n",
    "        transformed_X = scaler.fit_transform(transformed_X)\n",
    "        \n",
    "        results[trans_name_str] = {}\n",
    "        for clf_name, clf in classifiers.items():\n",
    "            # Evaluate the classifier with cross-validation\n",
    "            mean_accuracy, std_accuracy = evaluate_classifier_cv(clf, transformed_X, y)\n",
    "            results[trans_name_str][clf_name] = (mean_accuracy, std_accuracy)\n",
    "            print(f\"Transformation: {trans_name_str}, Classifier: {clf_name}, Mean Accuracy: {mean_accuracy:.3f}, Std Dev: {std_accuracy:.3f}\")\n",
    "\n",
    "    # Print the results\n",
    "    for trans_name, clf_results in results.items():\n",
    "        for clf_name, (mean_accuracy, std_accuracy) in clf_results.items():\n",
    "            print(f\"Transformation: {trans_name}, Classifier: {clf_name}, Mean Accuracy: {mean_accuracy:.3f}, Std Dev: {std_accuracy:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Computing  multifracs_i=0 ..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ant\\documents\\info2\\bits2beat-tests\\pymultifracs\\pymultifracs\\utils.py:87: RuntimeWarning: divide by zero encountered in power\n",
      "  return np.power(array, exponent)\n",
      "c:\\users\\ant\\documents\\info2\\bits2beat-tests\\pymultifracs\\pymultifracs\\utils.py:76: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  return array ** exponent\n",
      "c:\\users\\ant\\documents\\info2\\bits2beat-tests\\pymultifracs\\pymultifracs\\cumulants.py:265: RuntimeWarning: divide by zero encountered in log\n",
      "  log_T_X_j = np.log(T_X_j)\n",
      "c:\\users\\ant\\documents\\info2\\bits2beat-tests\\pymultifracs\\pymultifracs\\mfspectrum.py:117: RuntimeWarning: invalid value encountered in divide\n",
      "  R_j = temp / Z\n",
      "c:\\users\\ant\\documents\\info2\\bits2beat-tests\\pymultifracs\\pymultifracs\\mfspectrum.py:118: RuntimeWarning: divide by zero encountered in log2\n",
      "  V[:, ind_j, :] = fixednansum(R_j * np.log2(mrq_values_j), axis=1)\n",
      "c:\\users\\ant\\documents\\info2\\bits2beat-tests\\pymultifracs\\pymultifracs\\mfspectrum.py:118: RuntimeWarning: invalid value encountered in multiply\n",
      "  V[:, ind_j, :] = fixednansum(R_j * np.log2(mrq_values_j), axis=1)\n",
      "c:\\users\\ant\\documents\\info2\\bits2beat-tests\\pymultifracs\\pymultifracs\\mfspectrum.py:119: RuntimeWarning: divide by zero encountered in log2\n",
      "  U[:, ind_j, :] = np.log2(nj) + fixednansum((R_j * np.log2(R_j)),\n",
      "c:\\users\\ant\\documents\\info2\\bits2beat-tests\\pymultifracs\\pymultifracs\\mfspectrum.py:119: RuntimeWarning: invalid value encountered in multiply\n",
      "  U[:, ind_j, :] = np.log2(nj) + fixednansum((R_j * np.log2(R_j)),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1                        \n",
      "2                         ...\n",
      "3                         ...\n",
      "4                         ...\n",
      "5                         ...\n",
      "6                         ...\n",
      "7                         ...\n",
      "8                         ...\n",
      "9                         ...\n",
      "10                        ...\n",
      "11                       0 ...\n",
      "12                       1 ...\n",
      "13                       2 ...\n",
      "14                       3 ...\n",
      "15                       4 ...\n",
      "16                       5 ...\n",
      "17                       6 ...\n",
      "18                       7 ...\n",
      "19                       8 ...\n",
      "20                       9 ...\n",
      "21                       0 ...\n",
      "22                       1 ...\n",
      "23                       2 ...\n",
      "24                       3 ...\n",
      "25                       4 ...\n",
      "26                       5 ...\n",
      "27                       6 ...\n",
      "28                       7 ...\n",
      "29                       8 ...\n",
      "30                       9 ...\n",
      "31                       0 ...\n",
      "32                       1 ...\n",
      "33                       2 ...\n",
      "34                       3 ...\n",
      "35                       4 ...\n",
      "36                       5 ...\n",
      "37                       6 ...\n",
      "38                       7 ...\n",
      "39                       8 ...\n",
      "40                       9 ...\n",
      "41                       0 ...\n",
      "42                       1 ...\n",
      "43                       2 ...\n",
      "44                       3 ...\n",
      "45                       4 ...\n",
      "46                       5 ...\n",
      "47                       6 ...\n",
      "48                       7 ...\n",
      "49                       8 ...\n",
      "50                       9 ...\n",
      "51                       0 ...\n",
      "52                       1 ...\n",
      "53                       2 ...\n",
      "54                       3 ...\n",
      "55                       4 ...\n",
      "56                       5 ...\n",
      "57                       6 ...\n",
      "58                       7 ...\n",
      "59                       8 ...\n",
      "60                       9 ...\n",
      "61                       0 ...\n",
      "62                       1 ...\n",
      "63                       2 ...\n",
      "64                       3 ...\n",
      "65                       4 ...\n",
      "66                       5 ...\n",
      "67                       6 ...\n",
      "68                       7 ...\n",
      "69                       8 ...\n",
      "70                       9 ...\n",
      "71                       0 ...\n",
      "72                       1 ...\n",
      "73                       2 ...\n",
      "74                       3 ...\n",
      "75                       4 ...\n",
      "76                       5 ...\n",
      "77                       6 ...\n",
      "78                       7 ...\n",
      "79                       8 ...\n",
      "80                       9 ...\n",
      "81                       0 ...\n",
      "82                       1 ...\n",
      "83                       2 ...\n",
      "84                       3 ...\n",
      "85                       4 ...\n",
      "86                       5 ...\n",
      "87                       6 ...\n",
      "88                       7 ...\n",
      "89                       8 ...\n",
      "90                       9 ...\n",
      "91                       0 ...\n",
      "92                       1 ...\n",
      "93                       2 ...\n",
      "94                       3 ...\n",
      "95                       4 ...\n",
      "96                       5 ...\n",
      "97                       6 ...\n",
      "98                       7 ...\n",
      "99                       8 ...\n",
      "100                      9 ...\n",
      "101                      00 ...\n",
      "102                      01 ...\n",
      "103                      02 ...\n",
      "104                      03 ...\n",
      "105                      04 ...\n",
      "106                      05 ...\n",
      "107                      06 ...\n",
      "108                      07 ...\n",
      "109                      08 ...\n",
      "110                      09 ...\n",
      "111                      10 ...\n",
      "112                      11 ...\n",
      "113                      12 ...\n",
      "114                      13 ...\n",
      "115                      14 ...\n",
      "116                      15 ...\n",
      "117                      16 ...\n",
      "118                      17 ...\n",
      "119                      18 ...\n",
      "120                      19 ...\n",
      "121                      20 ...\n",
      "122                      21 ...\n",
      "123                      22 ...\n",
      "124                      23 ...\n",
      "125                      24 ...\n",
      "126                      25 ...\n",
      "127                      26 ...\n",
      "128                      27 ...\n",
      "Computing  multifracs_i=128 ..."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# Apply transformation\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[1;32m---> 14\u001b[0m     transformed_X \u001b[38;5;241m=\u001b[39m \u001b[43mdata_transformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_transformation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmultifracs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mi\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[36], line 82\u001b[0m, in \u001b[0;36mDataTransform.apply_transformation\u001b[1;34m(self, X, transformations)\u001b[0m\n\u001b[0;32m     80\u001b[0m transform_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregistry\u001b[38;5;241m.\u001b[39mget(trans_name)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComputing  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrans_name_kwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ...\u001b[39m\u001b[38;5;124m'\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 82\u001b[0m transformed_part \u001b[38;5;241m=\u001b[39m \u001b[43mtransform_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComputing  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrans_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ...\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m'\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[trans_name_kwargs] \u001b[38;5;241m=\u001b[39m transformed_part\n",
      "Cell \u001b[1;32mIn[34], line 191\u001b[0m, in \u001b[0;36mMultiFracsTransform.transform\u001b[1;34m(X, j1, j2, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m transformed_X \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39mones((n, \u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m--> 191\u001b[0m     dwt, lwt \u001b[38;5;241m=\u001b[39m \u001b[43mmfa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmf_analysis_full\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscaling_ranges\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mj1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuild_q_log\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_cumul\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mp_exp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgamint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m     sf, cumul, mfs, hmin \u001b[38;5;241m=\u001b[39m lwt\n\u001b[0;32m    200\u001b[0m     tau \u001b[38;5;241m=\u001b[39m interp1d(sf\u001b[38;5;241m.\u001b[39mq, sf\u001b[38;5;241m.\u001b[39mzeta[:,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m], kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\users\\ant\\documents\\info2\\bits2beat-tests\\pymultifracs\\pymultifracs\\mfa.py:194\u001b[0m, in \u001b[0;36mmf_analysis_full\u001b[1;34m(signal, scaling_ranges, normalization, gamint, weighted, wt_name, p_exp, q, n_cumul, bootstrap_weighted, estimates, R)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wt_transform\u001b[38;5;241m.\u001b[39mwt_leaders \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    192\u001b[0m     mrq \u001b[38;5;241m=\u001b[39m [mrq, wt_transform\u001b[38;5;241m.\u001b[39mwt_leaders]\n\u001b[1;32m--> 194\u001b[0m mf_data \u001b[38;5;241m=\u001b[39m \u001b[43mmf_analysis\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmrq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscaling_ranges\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweighted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweighted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_cumul\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_cumul\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbootstrap_weighted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbootstrap_weighted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mR\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mf_data\n",
      "File \u001b[1;32mc:\\users\\ant\\documents\\info2\\bits2beat-tests\\pymultifracs\\pymultifracs\\mfa.py:64\u001b[0m, in \u001b[0;36mmf_analysis\u001b[1;34m(mrq, scaling_ranges, weighted, n_cumul, q, bootstrap_weighted, R, estimates, robust, robust_kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m (n \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28mlen\u001b[39m(estimates)) \u001b[38;5;241m!=\u001b[39m (m \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28mlen\u001b[39m(mrq)):\n\u001b[0;32m     60\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     61\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of `estimates` = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match `mrq` = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     62\u001b[0m         )\n\u001b[1;32m---> 64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43m[\u001b[49m\u001b[43mmf_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaling_ranges\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweighted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_cumul\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbootstrap_weighted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimates\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrobust\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mrobust_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m             \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmrq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     69\u001b[0m scaling_ranges \u001b[38;5;241m=\u001b[39m sanitize_scaling_ranges(scaling_ranges, mrq\u001b[38;5;241m.\u001b[39mj2_eff())\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scaling_ranges) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\users\\ant\\documents\\info2\\bits2beat-tests\\pymultifracs\\pymultifracs\\mfa.py:64\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m (n \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28mlen\u001b[39m(estimates)) \u001b[38;5;241m!=\u001b[39m (m \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28mlen\u001b[39m(mrq)):\n\u001b[0;32m     60\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     61\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of `estimates` = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match `mrq` = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     62\u001b[0m         )\n\u001b[1;32m---> 64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ([\u001b[43mmf_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaling_ranges\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweighted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_cumul\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbootstrap_weighted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimates\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrobust\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mrobust_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m              \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(mrq)])\n\u001b[0;32m     69\u001b[0m scaling_ranges \u001b[38;5;241m=\u001b[39m sanitize_scaling_ranges(scaling_ranges, mrq\u001b[38;5;241m.\u001b[39mj2_eff())\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scaling_ranges) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\users\\ant\\documents\\info2\\bits2beat-tests\\pymultifracs\\pymultifracs\\mfa.py:121\u001b[0m, in \u001b[0;36mmf_analysis\u001b[1;34m(mrq, scaling_ranges, weighted, n_cumul, q, bootstrap_weighted, R, estimates, robust, robust_kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     cumul \u001b[38;5;241m=\u001b[39m Cumulants\u001b[38;5;241m.\u001b[39mfrom_dict(parameters)\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m estimates:\n\u001b[1;32m--> 121\u001b[0m     spec \u001b[38;5;241m=\u001b[39m \u001b[43mMultifractalSpectrum\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# pylint: disable=unbalanced-tuple-unpacking\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mrq\u001b[38;5;241m.\u001b[39mformalism \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwavelet coef\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\users\\ant\\documents\\info2\\bits2beat-tests\\pymultifracs\\pymultifracs\\multiresquantity.py:72\u001b[0m, in \u001b[0;36mMultiResolutionQuantityBase.from_dict\u001b[1;34m(cls, d)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_dict\u001b[39m(\u001b[38;5;28mcls\u001b[39m, d):\n\u001b[0;32m     49\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Method to instanciate a dataclass by passing a dictionary with\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    extra keywords\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m              parameters, similarly to introducing a \\*\\*kwargs parameter.\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<string>:7\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, mrq, scaling_ranges, q, bootstrapped_mfa, weighted)\u001b[0m\n",
      "File \u001b[1;32mc:\\users\\ant\\documents\\info2\\bits2beat-tests\\pymultifracs\\pymultifracs\\mfspectrum.py:91\u001b[0m, in \u001b[0;36mMultifractalSpectrum.__post_init__\u001b[1;34m(self, mrq, bootstrapped_mfa)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bootstrapped_mfa \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrapped_mrq \u001b[38;5;241m=\u001b[39m bootstrapped_mfa\u001b[38;5;241m.\u001b[39mspectrum\n\u001b[1;32m---> 91\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmrq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\ant\\documents\\info2\\bits2beat-tests\\pymultifracs\\pymultifracs\\mfspectrum.py:118\u001b[0m, in \u001b[0;36mMultifractalSpectrum._compute\u001b[1;34m(self, mrq)\u001b[0m\n\u001b[0;32m    116\u001b[0m     Z[Z \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan\n\u001b[0;32m    117\u001b[0m     R_j \u001b[38;5;241m=\u001b[39m temp \u001b[38;5;241m/\u001b[39m Z\n\u001b[1;32m--> 118\u001b[0m     V[:, ind_j, :] \u001b[38;5;241m=\u001b[39m \u001b[43mfixednansum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mR_j\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmrq_values_j\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m     U[:, ind_j, :] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog2(nj) \u001b[38;5;241m+\u001b[39m fixednansum((R_j \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog2(R_j)),\n\u001b[0;32m    120\u001b[0m                                                axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    122\u001b[0m U[np\u001b[38;5;241m.\u001b[39misinf(U)] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan\n",
      "File \u001b[1;32mc:\\users\\ant\\documents\\info2\\bits2beat-tests\\pymultifracs\\pymultifracs\\utils.py:127\u001b[0m, in \u001b[0;36mfixednansum\u001b[1;34m(a, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m q\n\u001b[0;32m    120\u001b[0m stat2fun \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmean,\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmedian,\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mnanmin,\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mnanmax}\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfixednansum\u001b[39m(a, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    128\u001b[0m     mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39misnan(a)\u001b[38;5;241m.\u001b[39mall(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    129\u001b[0m     res \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnansum(a, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Initialize the data transformer\n",
    "    data_transformer = DataTransform(registry)\n",
    "\n",
    "    # Example input data\n",
    "    data = np.load('ecgs_labels.npy')\n",
    "    X, y = data[:,:-1], data[:,-1] # Example input data\n",
    "    p = np.random.permutation(X.shape[0])\n",
    "    X = X[p,:]\n",
    "    y =y[p]\n",
    "    for i in range(X.shape[0]):\n",
    "        # Apply transformation\n",
    "        print(i)\n",
    "        transformed_X = data_transformer.apply_transformation(X[i,:][None,:], ['multifracs',{'i':i}])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
