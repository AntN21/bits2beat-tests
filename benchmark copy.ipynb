{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark for signal representation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Multifractal analysis (1ere approche)\n",
    "\n",
    "- Discrete Fourier Transform (DFT) $\\checkmark$\n",
    "- Spectrogram\n",
    "- Autoregression $\\checkmark$\n",
    "- Shannon encoding $\\checkmark$\n",
    "- Wavelets (en cours)\n",
    "\n",
    "- Local symbolic features\n",
    "- SAX representation\n",
    "- Approximate entropy\n",
    "\n",
    "ML\n",
    "\n",
    "- Autoencoder\n",
    "\n",
    "- RNN\n",
    "- LSTM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import pywt\n",
    "\n",
    "import inspect\n",
    "import pymultifracs.mfa as mfa\n",
    "from pymultifracs.utils import build_q_log\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# import pandas_datareader as pdr\n",
    "# import seaborn as sns\n",
    "# from statsmodels.tsa.api import acf, graphics, pacf\n",
    "from statsmodels.tsa.ar_model import AutoReg, ar_select_order\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecgs_labels = np.load('ecgs_labels.npy')\n",
    "\n",
    "X, y = ecgs_labels[:,:-1], ecgs_labels[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "class DataTransform:\n",
    "    def __init__(self) -> None:\n",
    "        self.transformed_X = None\n",
    "\n",
    "    @property\n",
    "    def X(self):\n",
    "        return self.transformed_X\n",
    "    \n",
    "    @property\n",
    "    def shape(self):\n",
    "        if self.transformed_X is not None:\n",
    "            return self.transformed_X.shape\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    @staticmethod\n",
    "    def identity(X, **kwargs):\n",
    "        return X\n",
    "    \n",
    "    @staticmethod\n",
    "    def fourier(X, new_dimension=None, **kwargs):\n",
    "        fourier_transform = np.fft.fft(X, n=new_dimension)\n",
    "        modulus = np.abs(fourier_transform)\n",
    "        return modulus\n",
    "    \n",
    "    @staticmethod\n",
    "    def wavedec(X, level=4, wavelet='db1', mode='symmetric', **kwargs):\n",
    "        array = np.array(X)\n",
    "        coeffs = pywt.wavedec(array, wavelet, mode=mode, level=level)\n",
    "        coeffs_torch = [torch.tensor(c) for c in coeffs[:1]]\n",
    "        return torch.cat(coeffs_torch, dim=-1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def dwt(X, wavelet='db1', mode='symmetric', **kwargs):\n",
    "        array = np.arrat(X)\n",
    "        coeffs = pywt.dwt(array, wavelet, mode=mode)\n",
    "        coeffs_torch = [torch.tensor(c) for c in coeffs]\n",
    "        return torch.cat(coeffs_torch, dim=-1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_ar_coefficients(X, k, **kwargs):\n",
    "        n, p = X.shape\n",
    "        X = np.array(X)\n",
    "        ar_coefficients = np.zeros((n, k))\n",
    "        for i in range(n):\n",
    "            model = AutoReg(X[i], lags=k).fit()\n",
    "            ar_coefficients[i] = model.params[1:k+1] \n",
    "        return ar_coefficients\n",
    "    \n",
    "    @staticmethod\n",
    "    def autoreg(X, k, **kwargs):\n",
    "        return DataTransform.get_ar_coefficients(X, k)\n",
    "    \n",
    "    @staticmethod\n",
    "    def shannon_encoding(X, level=4, wavelet='db1', mode='symmetric', **kwargs):\n",
    "        def compute_shannon_entropy(signal):\n",
    "            return -np.nansum(signal**2 * np.log(signal**2))\n",
    "        \n",
    "        n_examples = X.shape[0]\n",
    "        wp = pywt.WaveletPacket(X[0, :], wavelet=\"sym8\", maxlevel=3)\n",
    "        packet_names = [node.path for node in wp.get_level(3, \"natural\")]\n",
    "        \n",
    "        feature_matrix_wav_packet_entropy = np.full((n_examples, 8), np.nan)\n",
    "        for i in range(len(X)):\n",
    "            wp = pywt.WaveletPacket(X[i, :], wavelet=\"sym8\", maxlevel=3)\n",
    "            for j in range(len(packet_names)):\n",
    "                new_wp = pywt.WaveletPacket(data=None, wavelet=\"sym8\", maxlevel=3)\n",
    "                new_wp[packet_names[j]] = wp[packet_names[j]].data\n",
    "                reconstructed_signal = new_wp.reconstruct(update=False)\n",
    "                feature_matrix_wav_packet_entropy[i, j] = compute_shannon_entropy(reconstructed_signal)\n",
    "        return feature_matrix_wav_packet_entropy\n",
    "    \n",
    "    @staticmethod\n",
    "    def wavelet_leaders(X, j1=2, j2=6, **kwargs):\n",
    "        n = X.shape[0] if X.ndim > 1 else 1\n",
    "        transformed_X = -np.ones((n, 2))\n",
    "        for i in range(X.shape[0]):\n",
    "            dwt, lwt = mfa.mf_analysis_full(\n",
    "                X[i],\n",
    "                scaling_ranges=[(j1, j2)],\n",
    "                q=mfa.build_q_log(1, 10, 20),\n",
    "                n_cumul=2,\n",
    "                p_exp=np.inf,\n",
    "                gamint=0.0\n",
    "            )\n",
    "            sf, cumul, mfs, hmin = lwt\n",
    "            transformed_X[i, :] = sf.H.item(), cumul.log_cumulants[1].item()\n",
    "        return transformed_X\n",
    "\n",
    "    def apply_transformation(self, X, transformation_name, **kwargs):\n",
    "        transformation_methods = {\n",
    "            'identity': self.identity,\n",
    "            'fourier': self.fourier,\n",
    "            'wavedec': self.wavedec,\n",
    "            'dwt': self.dwt,\n",
    "            'autoreg': self.autoreg,\n",
    "            'shannon_encoding': self.shannon_encoding,\n",
    "            'wavelet_leaders': self.wavelet_leaders,\n",
    "        }\n",
    "        \n",
    "        if transformation_name in transformation_methods.keys():\n",
    "            method = transformation_methods[transformation_name]\n",
    "            return method(X, **kwargs)\n",
    "        else:\n",
    "            raise ValueError(f\"Transformation {transformation_name} not recognized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransform:\n",
    "    def __init__(self) -> None:\n",
    "        self.transformed_X = None\n",
    "\n",
    "    @property\n",
    "    def X(self):\n",
    "        return self.transformed_X\n",
    "    \n",
    "    @property\n",
    "    def shape(self):\n",
    "        if self.transformed_X is not None:\n",
    "            return self.transformed_X.shape\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    @staticmethod\n",
    "    def identity(X):\n",
    "        return X\n",
    "    \n",
    "    @staticmethod\n",
    "    def fourier(X, new_dimension=None):\n",
    "        fourier_transform = np.fft.fft(X, n=new_dimension)\n",
    "        modulus = np.abs(fourier_transform)\n",
    "        return modulus\n",
    "    \n",
    "    @staticmethod\n",
    "    def wavedec(X, level=4, wavelet='db1', mode='symmetric'):\n",
    "        array = np.array(X)\n",
    "        coeffs = pywt.wavedec(array, wavelet, mode=mode, level=level)\n",
    "        coeffs_torch = [torch.tensor(c) for c in coeffs[:1]]\n",
    "        return np.array(torch.cat(coeffs_torch, dim=-1))\n",
    "    \n",
    "    @staticmethod\n",
    "    def dwt(X, wavelet='db1', mode='symmetric'):\n",
    "        array = np.array(X)\n",
    "        coeffs = pywt.dwt(array, wavelet, mode=mode)\n",
    "        coeffs_torch = [torch.tensor(c) for c in coeffs[:1]]\n",
    "        return np.array(torch.cat(coeffs_torch, dim=-1))\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_ar_coefficients(X, k):\n",
    "        n, p = X.shape\n",
    "        ar_coefficients = np.zeros((n, k))\n",
    "        for i in range(n):\n",
    "            model = AutoReg(X[i], lags=k).fit()\n",
    "            ar_coefficients[i] = model.params[1:k+1] \n",
    "        return ar_coefficients\n",
    "    \n",
    "    @staticmethod\n",
    "    def autoreg(X, k):\n",
    "        return DataTransform.get_ar_coefficients(X, k)\n",
    "    \n",
    "    @staticmethod\n",
    "    def shannon_encoding(X, level=4, wavelet='db1', mode='symmetric'):\n",
    "        def compute_shannon_entropy(signal):\n",
    "            return -np.nansum(signal**2 * np.log(signal**2))\n",
    "        \n",
    "        n_examples = X.shape[0]\n",
    "        wp = pywt.WaveletPacket(X[0, :], wavelet=\"sym8\", maxlevel=3)\n",
    "        packet_names = [node.path for node in wp.get_level(3, \"natural\")]\n",
    "        \n",
    "        feature_matrix_wav_packet_entropy = np.full((n_examples, 8), np.nan)\n",
    "        for i in range(len(X)):\n",
    "            wp = pywt.WaveletPacket(X[i, :], wavelet=\"sym8\", maxlevel=3)\n",
    "            for j in range(len(packet_names)):\n",
    "                new_wp = pywt.WaveletPacket(data=None, wavelet=\"sym8\", maxlevel=3)\n",
    "                new_wp[packet_names[j]] = wp[packet_names[j]].data\n",
    "                reconstructed_signal = new_wp.reconstruct(update=False)\n",
    "                feature_matrix_wav_packet_entropy[i, j] = compute_shannon_entropy(reconstructed_signal)\n",
    "        return feature_matrix_wav_packet_entropy\n",
    "    \n",
    "    @staticmethod\n",
    "    def wavelet_leaders(X, j1=2, j2=6):\n",
    "        n = X.shape[0] if X.ndim > 1 else 1\n",
    "        transformed_X = -np.ones((n, 2))\n",
    "        for i in range(X.shape[0]):\n",
    "            dwt, lwt = mfa.mf_analysis_full(\n",
    "                X[i],\n",
    "                scaling_ranges=[(j1, j2)],\n",
    "                q=mfa.build_q_log(1, 10, 20),\n",
    "                n_cumul=2,\n",
    "                p_exp=np.inf,\n",
    "                gamint=0.0\n",
    "            )\n",
    "            sf, cumul, mfs, hmin = lwt\n",
    "            transformed_X[i, :] = sf.H.item(), cumul.log_cumulants[1].item()\n",
    "        return transformed_X\n",
    "\n",
    "    def apply_transformation(self, X, transformation_name, **kwargs):\n",
    "        transformation_methods = {\n",
    "            'identity': self.identity,\n",
    "            'fourier': self.fourier,\n",
    "            'wavedec': self.wavedec,\n",
    "            'dwt': self.dwt,\n",
    "            'autoreg': self.autoreg,\n",
    "            'shannon_encoding': self.shannon_encoding,\n",
    "            'wavelet_leaders': self.wavelet_leaders,\n",
    "        }\n",
    "        \n",
    "        if transformation_name in transformation_methods.keys():\n",
    "            method = transformation_methods[transformation_name]\n",
    "            # Get the method's argument names\n",
    "            method_args = inspect.signature(method).parameters\n",
    "            # Filter kwargs to only include the ones that are relevant for the method\n",
    "            filtered_kwargs = {k: v for k, v in kwargs.items() if k in method_args}\n",
    "            return method(X, **filtered_kwargs)\n",
    "        else:\n",
    "            raise ValueError(f\"Transformation {transformation_name} not recognized.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation: fourier, Shape: (1170, 64)\n",
      "Transformation: wavedec, Shape: (1170, 16250)\n",
      "Transformation: autoreg, Shape: (1170, 5)\n"
     ]
    }
   ],
   "source": [
    "data_transformer = DataTransform()\n",
    "# X = np.randn(100, 10)  # Example input data\n",
    "\n",
    "# # Apply different transformations\n",
    "# transformed_X_identity = data_transformer.apply_transformation(X, 'identity')\n",
    "# transformed_X_fourier = data_transformer.apply_transformation(X, 'fourier',new_dimension = 8)\n",
    "# transformed_X_wavedec = data_transformer.apply_transformation(X, 'wavedec', level=4)\n",
    "# transformed_X_autoreg = data_transformer.apply_transformation(X, 'autoreg', k=3)\n",
    "\n",
    "# Iterate over multiple transformations\n",
    "transformations = [ 'fourier', 'wavedec', 'autoreg']\n",
    "for trans in transformations:\n",
    "    transformed_X = data_transformer.apply_transformation(X, trans, level=2 if trans == 'wavedec' else 3,  new_dimension = 64,k = 5)\n",
    "    print(f\"Transformation: {trans}, Shape: {transformed_X.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation: fourier, Classifier: SVM, Accuracy: 0.987\n",
      "Transformation: fourier, Classifier: DecisionTree, Accuracy: 0.979\n",
      "Transformation: fourier, Classifier: RandomForest, Accuracy: 0.983\n",
      "Transformation: wavedec, Classifier: SVM, Accuracy: 0.880\n",
      "Transformation: wavedec, Classifier: DecisionTree, Accuracy: 0.607\n",
      "Transformation: wavedec, Classifier: RandomForest, Accuracy: 0.816\n",
      "Transformation: autoreg, Classifier: SVM, Accuracy: 0.846\n",
      "Transformation: autoreg, Classifier: DecisionTree, Accuracy: 0.932\n",
      "Transformation: autoreg, Classifier: RandomForest, Accuracy: 0.970\n",
      "Transformation: fourier, Classifier: SVM, Accuracy: 0.987\n",
      "Transformation: fourier, Classifier: DecisionTree, Accuracy: 0.979\n",
      "Transformation: fourier, Classifier: RandomForest, Accuracy: 0.983\n",
      "Transformation: wavedec, Classifier: SVM, Accuracy: 0.880\n",
      "Transformation: wavedec, Classifier: DecisionTree, Accuracy: 0.607\n",
      "Transformation: wavedec, Classifier: RandomForest, Accuracy: 0.816\n",
      "Transformation: autoreg, Classifier: SVM, Accuracy: 0.846\n",
      "Transformation: autoreg, Classifier: DecisionTree, Accuracy: 0.932\n",
      "Transformation: autoreg, Classifier: RandomForest, Accuracy: 0.970\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming DataTransform class is already defined as provided\n",
    "\n",
    "# Initialize the data transformer\n",
    "data_transformer = DataTransform()\n",
    "\n",
    "# # Example input data\n",
    "# X = torch.randn(100, 10)  # Example input data\n",
    "# y = np.random.randint(0, 2, 100)  # Example labels\n",
    "\n",
    "# Define the classifiers to be tested\n",
    "classifiers = {\n",
    "    'SVM': SVC(),\n",
    "    'DecisionTree': DecisionTreeClassifier(),\n",
    "    'RandomForest': RandomForestClassifier()\n",
    "}\n",
    "\n",
    "# Define the transformations to be tested\n",
    "transformations = {\n",
    "    #'identity': {},\n",
    "    'fourier': {},\n",
    "    'wavedec': {'level': 3},\n",
    "    'autoreg': {'k': 3}\n",
    "}\n",
    "\n",
    "# Function to evaluate a classifier on transformed data\n",
    "def evaluate_classifier(classifier, X_train, X_test, y_train, y_test):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Loop over each transformation and each classifier\n",
    "results = {}\n",
    "for trans_name, trans_kwargs in transformations.items():\n",
    "    # Apply transformation\n",
    "    transformed_X = data_transformer.apply_transformation(np.array(X), trans_name, **trans_kwargs)\n",
    "    # Ensure the transformed data is in the right shape\n",
    "    if isinstance(transformed_X, torch.Tensor):\n",
    "        transformed_X = transformed_X.numpy()\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(transformed_X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    results[trans_name] = {}\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        # Evaluate the classifier\n",
    "        accuracy = evaluate_classifier(clf, X_train, X_test, y_train, y_test)\n",
    "        results[trans_name][clf_name] = accuracy\n",
    "        print(f\"Transformation: {trans_name}, Classifier: {clf_name}, Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "# Print the results\n",
    "for trans_name, clf_results in results.items():\n",
    "    for clf_name, accuracy in clf_results.items():\n",
    "        print(f\"Transformation: {trans_name}, Classifier: {clf_name}, Accuracy: {accuracy:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation: fourier, Classifier: SVM, Mean Accuracy: 0.9854700854700855, Std Dev: 0.02485989670469912\n",
      "Transformation: fourier, Classifier: DecisionTree, Mean Accuracy: 0.982905982905983, Std Dev: 0.006620484352491331\n",
      "Transformation: fourier, Classifier: RandomForest, Mean Accuracy: 0.9743589743589742, Std Dev: 0.011143935735389146\n",
      "Transformation: wavedec, Classifier: SVM, Mean Accuracy: 0.9179487179487179, Std Dev: 0.03074547991214521\n",
      "Transformation: wavedec, Classifier: DecisionTree, Mean Accuracy: 0.6863247863247863, Std Dev: 0.14203472189976743\n",
      "Transformation: wavedec, Classifier: RandomForest, Mean Accuracy: 0.8692307692307694, Std Dev: 0.04130955888408401\n",
      "Transformation: autoreg, Classifier: SVM, Mean Accuracy: 0.8931623931623932, Std Dev: 0.01709401709401708\n",
      "Transformation: autoreg, Classifier: DecisionTree, Mean Accuracy: 0.8923076923076921, Std Dev: 0.03892409414268617\n",
      "Transformation: autoreg, Classifier: RandomForest, Mean Accuracy: 0.9128205128205128, Std Dev: 0.04050596790110354\n",
      "Transformation: fourier, Classifier: SVM, Mean Accuracy: 0.9854700854700855, Std Dev: 0.02485989670469912\n",
      "Transformation: fourier, Classifier: DecisionTree, Mean Accuracy: 0.982905982905983, Std Dev: 0.006620484352491331\n",
      "Transformation: fourier, Classifier: RandomForest, Mean Accuracy: 0.9743589743589742, Std Dev: 0.011143935735389146\n",
      "Transformation: wavedec, Classifier: SVM, Mean Accuracy: 0.9179487179487179, Std Dev: 0.03074547991214521\n",
      "Transformation: wavedec, Classifier: DecisionTree, Mean Accuracy: 0.6863247863247863, Std Dev: 0.14203472189976743\n",
      "Transformation: wavedec, Classifier: RandomForest, Mean Accuracy: 0.8692307692307694, Std Dev: 0.04130955888408401\n",
      "Transformation: autoreg, Classifier: SVM, Mean Accuracy: 0.8931623931623932, Std Dev: 0.01709401709401708\n",
      "Transformation: autoreg, Classifier: DecisionTree, Mean Accuracy: 0.8923076923076921, Std Dev: 0.03892409414268617\n",
      "Transformation: autoreg, Classifier: RandomForest, Mean Accuracy: 0.9128205128205128, Std Dev: 0.04050596790110354\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming DataTransform class is already defined as provided\n",
    "\n",
    "# Initialize the data transformer\n",
    "data_transformer = DataTransform()\n",
    "\n",
    "# Define the classifiers to be tested\n",
    "classifiers = {\n",
    "    'SVM': SVC(),\n",
    "    'DecisionTree': DecisionTreeClassifier(),\n",
    "    'RandomForest': RandomForestClassifier()\n",
    "}\n",
    "\n",
    "# Define the transformations to be tested\n",
    "transformations = {\n",
    "    #'identity': {},\n",
    "    'fourier': {},\n",
    "    'wavedec': {'level': 4},\n",
    "    'autoreg': {'k': 3}\n",
    "}\n",
    "\n",
    "# Function to evaluate a classifier using cross-validation\n",
    "def evaluate_classifier_cv(classifier, X, y):\n",
    "    scores = cross_val_score(classifier, X, y, cv=5)  # 5-fold cross-validation\n",
    "    return np.mean(scores), np.std(scores)\n",
    "\n",
    "# Loop over each transformation and each classifier\n",
    "results = {}\n",
    "for trans_name, trans_kwargs in transformations.items():\n",
    "    # Apply transformation\n",
    "    transformed_X = data_transformer.apply_transformation(X, trans_name, **trans_kwargs)\n",
    "    # Ensure the transformed data is in the right shape\n",
    "    if isinstance(transformed_X, torch.Tensor):\n",
    "        transformed_X = transformed_X.numpy()\n",
    "    \n",
    "    # Standardize the data (important for some classifiers like SVM)\n",
    "    scaler = StandardScaler()\n",
    "    transformed_X = scaler.fit_transform(transformed_X)\n",
    "    \n",
    "    results[trans_name] = {}\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        # Evaluate the classifier with cross-validation\n",
    "        mean_accuracy, std_accuracy = evaluate_classifier_cv(clf, transformed_X, y)\n",
    "        results[trans_name][clf_name] = (mean_accuracy, std_accuracy)\n",
    "        print(f\"Transformation: {trans_name}, Classifier: {clf_name}, Mean Accuracy: {mean_accuracy:.3f}, Std Dev: {std_accuracy:.3f}\")\n",
    "\n",
    "# Print the results\n",
    "for trans_name, clf_results in results.items():\n",
    "    for clf_name, (mean_accuracy, std_accuracy) in clf_results.items():\n",
    "        print(f\"Transformation: {trans_name}, Classifier: {clf_name}, Mean Accuracy: {mean_accuracy:.3f}, Std Dev: {std_accuracy:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
