{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark for signal representation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Multifractal analysis (1ere approche)\n",
    "\n",
    "- Discrete Fourier Transform (DFT) $\\checkmark$\n",
    "- Spectrogram\n",
    "- Autoregression $\\checkmark$\n",
    "- Shannon encoding $\\checkmark$\n",
    "- Wavelets (en cours)\n",
    "\n",
    "- Local symbolic features\n",
    "- SAX representation\n",
    "- Approximate entropy\n",
    "\n",
    "ML\n",
    "\n",
    "- Autoencoder\n",
    "\n",
    "- RNN\n",
    "- LSTM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import pywt\n",
    "\n",
    "# import pymultifracs.mfa as mfa\n",
    "# from pymultifracs.utils import build_q_log\n",
    "# from statsmodels.tsa.ar_model import AutoReg, ar_select_order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install import_ipynb\n",
    "# %pip install  --user git+https://github.com/neurospin/pymultifracs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from transformations.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from transformations import DataTransform,TransformationRegistry, IdentityTransform, FourierTransform, LowFourierTransform, LowPsdTransform, WaveDecTransform, DwtTransform, CwtTransform, AutoRegTransform, ShannonEncodingTransform, WaveletLeadersTransform, CrossCorTransform, AutoCorTransform, MultiFracsTransform, AutoEncoderTransform  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the registry\n",
    "registry = TransformationRegistry()\n",
    "\n",
    "# Register transformations\n",
    "registry.register('identity', IdentityTransform)\n",
    "registry.register('fourier', FourierTransform)\n",
    "registry.register('low_fourier', LowFourierTransform)\n",
    "registry.register('low_psd', LowPsdTransform)\n",
    "registry.register('wavedec', WaveDecTransform)\n",
    "registry.register('dwt', DwtTransform)\n",
    "registry.register('cwt', CwtTransform)\n",
    "registry.register('autoreg', AutoRegTransform)\n",
    "registry.register('shannon_encoding', ShannonEncodingTransform)\n",
    "registry.register('wavelet_leaders', WaveletLeadersTransform)\n",
    "registry.register('multifracs', MultiFracsTransform)\n",
    "registry.register('crosscor', CrossCorTransform)\n",
    "registry.register('autocor', AutoCorTransform)\n",
    "registry.register('autoencoder', AutoEncoderTransform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load\n",
    "\n",
    "Link here [ecgs_labels.npy](https://drive.google.com/file/d/1cbUKH9qGOeIZD6Mf73plMkyXpq56mwIu/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecgs_labels = np.load('ecgs_labels.npy')\n",
    "\n",
    "X, y = ecgs_labels[1:,:-1], ecgs_labels[1:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y = np.load('hrv_signals.npy'), np.load('hrv_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrvs_labels = np.load('hrv_data.npy')\n",
    "\n",
    "X, y = hrvs_labels[:,:-1], hrvs_labels[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(X).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape : (68, 71933)\n"
     ]
    }
   ],
   "source": [
    "n,p = X.shape\n",
    "\n",
    "print(f'X.shape : {n,p}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j2max = min(12,int(np.log2(p) - 3))\n",
    "j2max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ = 65000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation: identity, Shape: (10, 65000)\n",
      "Computing  fourier ..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation: fourier, Shape: (10, 65000)\n",
      "Transformation: low_fourier, Shape: (10, 1092)\n",
      "Transformation: low_psd, Shape: (10, 1092)\n",
      "Transformation: wavedec, Shape: (10, 4063)\n",
      "Transformation: dwt, Shape: (10, 32500)\n",
      "Transformation: cwt, Shape: (10, 10)\n",
      "Transformation: autoreg, Shape: (10, 3)\n",
      "Transformation: shannon_encoding, Shape: (10, 8)\n",
      "Transformation: wavelet_leaders, Shape: (10, 2)\n",
      "Transformation: multifracs, Shape: (10, 3)\n",
      "Transformation: crosscor, Shape: (10, 10)\n",
      "Transformation: autocor, Shape: (10, 26000)\n",
      "Transformation: autoencoder, Shape: (10, 16)\n"
     ]
    }
   ],
   "source": [
    "data_transformer = DataTransform(registry,save_data=False)\n",
    "for trans_names in registry.transformations.keys():\n",
    "        trans_names_str = [str(name) for name in trans_names]\n",
    "        trans_name_str = '+'.join(trans_names_str) if isinstance(trans_names, list) else trans_names\n",
    "        kwargs = trans_names[1] if isinstance(trans_names, list) and len(trans_names) > 1 else {}\n",
    "        trans_names = trans_names[0] if isinstance(trans_names, list) else trans_names\n",
    "        # Apply transformation\n",
    "        transformed_X = data_transformer.apply_transformation(np.random.randn((10*p_)).reshape((10,p_)), trans_names, **kwargs)\n",
    "        \n",
    "        print(f\"Transformation: {trans_name_str}, Shape: {transformed_X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the data transformer\n",
    "data_transformer = DataTransform(registry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "# Define the classifiers to be tested\n",
    "classifiers = {\n",
    "    'SVM': SVC(),\n",
    "    'DecisionTree': DecisionTreeClassifier(),\n",
    "    'RandomForest': RandomForestClassifier()\n",
    "}\n",
    "\n",
    "# Define the transformations to be tested\n",
    "transformations = [\n",
    "    # ['identity'],\n",
    "    ['crosscor'],\n",
    "    ['autocor', {'m':5000,'k':4}],\n",
    "    ['fourier', {'new_dimension':40}],\n",
    "    ['low_fourier'],\n",
    "    ['low_psd'],\n",
    "    ['cwt',{'pca_components' : 10}],\n",
    "    ['wavedec'],\n",
    "    ['autoreg', {'k': 3}],\n",
    "    ['shannon_encoding'],\n",
    "    ['wavelet_leaders'],\n",
    "    ['multifracs'],\n",
    "    ['multifracs', {'j1':1,'j2':12}],\n",
    "    [['wavelet_leaders','shannon_encoding']],\n",
    "    [['wavelet_leaders','multifracs']],\n",
    "    [['fourier','multifracs',], {'new_dimension':40}],\n",
    "    [['fourier','multifracs',], {'new_dimension':40}],\n",
    "    [['fourier','multifracs','shannon_encoding'], {'new_dimension':40}],\n",
    "    [['low_fourier','multifracs','autoreg'], {'k':3}],\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to evaluate a classifier using cross-validation\n",
    "def evaluate_classifier_cv(classifier, X, y):\n",
    "    scores = cross_val_score(classifier, X, y, cv=5)  # 5-fold cross-validation\n",
    "    return np.mean(scores), np.std(scores)\n",
    "\n",
    "# Loop over each transformation and each classifier\n",
    "results = {}\n",
    "\n",
    "for trans_names in transformations:\n",
    "    # print()\n",
    "    trans_names_str = [str(name) for name in trans_names]\n",
    "    trans_name_str = '+'.join(trans_names_str) if isinstance(trans_names, list) else trans_names\n",
    "    kwargs = trans_names[1] if isinstance(trans_names, list) and len(trans_names) > 1 else {}\n",
    "    trans_names = trans_names[0] if isinstance(trans_names, list) else trans_names\n",
    "    \n",
    "    # Apply transformation\n",
    "    transformed_X = data_transformer.apply_transformation(X, trans_names, **kwargs)\n",
    "    print(f\"Transformation: {trans_name_str}, Shape: {transformed_X.shape}\" )\n",
    "    # Standardize the data (important for some classifiers like SVM)\n",
    "    scaler = StandardScaler()\n",
    "    transformed_X = scaler.fit_transform(transformed_X)\n",
    "    \n",
    "    results[trans_name_str] = {}\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        # Evaluate the classifier with cross-validation\n",
    "        mean_accuracy, std_accuracy = evaluate_classifier_cv(clf, transformed_X, y)\n",
    "        results[trans_name_str][clf_name] = (mean_accuracy, std_accuracy)\n",
    "        print(f\"Transformation: {trans_name_str}, Classifier: {clf_name}, Mean Accuracy: {mean_accuracy:.3f}, Std Dev: {std_accuracy:.3f}\")\n",
    "\n",
    "    print()\n",
    "# Print the results\n",
    "for trans_name, clf_results in results.items():\n",
    "    print()\n",
    "    for clf_name, (mean_accuracy, std_accuracy) in clf_results.items():\n",
    "        print(f\"Transformation: {trans_name}, Classifier: {clf_name}, Mean Accuracy: {mean_accuracy:.3f}, Std Dev: {std_accuracy:.3f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['autoreg', {'k': 5}]], [['autoreg', {'k': 3}], ['multifracs', {'j1': 1, 'j2': 12}]], ['low_fourier'], ['crosscor', ['autoreg', {'k': 5}], ['autoreg', {'k': 3}]], [['multifracs', {'j1': 1, 'j2': 12}]], ['low_fourier'], [['multifracs', {'j1': 1, 'j2': 12}], ['autoencoder', {'fourier_transform': True}]], ['shannon_encoding'], ['shannon_encoding', 'low_psd', ['autoreg', {'k': 5}], ['multifracs', {'j1': 1, 'j2': 12}]], ['low_fourier', 'low_psd', 'crosscor'], [['autoreg', {'k': 5}], ['autoreg', {'k': 3}], 'low_psd', 'crosscor'], [['autoreg', {'k': 3}], 'crosscor', ['autoreg', {'k': 5}], ['autoencoder', {'fourier_transform': True}]], [['multifracs', {'j1': 1, 'j2': 12}], ['autoreg', {'k': 3}], 'shannon_encoding', ['autoencoder', {'fourier_transform': True}]], [['multifracs', {'j1': 1, 'j2': 12}], ['autoreg', {'k': 3}], 'crosscor'], [['multifracs', {'j1': 1, 'j2': 12}], ['autoreg', {'k': 5}], ['autoencoder', {'fourier_transform': True}], 'crosscor'], [['autoencoder', {'fourier_transform': True}], 'low_psd', 'crosscor', ['autoreg', {'k': 5}]], [['autoencoder', {'fourier_transform': True}], ['multifracs', {'j1': 1, 'j2': 12}]], [['autoencoder', {'fourier_transform': True}], 'crosscor', 'shannon_encoding'], [['autoreg', {'k': 3}], 'crosscor', 'shannon_encoding'], ['low_psd', 'low_fourier', 'shannon_encoding']]\n",
      "\n",
      "Transformations n°1: autoreg_k=5 (68, 5)\n",
      "Classifier: SVM, Mean Accuracy: 0.810, Std Dev: 0.054\n",
      "Classifier: DecisionTree, Mean Accuracy: 0.708, Std Dev: 0.098\n",
      "Classifier: RandomForest, Mean Accuracy: 0.829, Std Dev: 0.160\n",
      "\n",
      "Computing  multifracs_j1=1_j2=12 ..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aejog\\anaconda3\\Lib\\site-packages\\pymultifracs\\utils.py:87: RuntimeWarning: divide by zero encountered in power\n",
      "  return np.power(array, exponent)\n",
      "c:\\Users\\aejog\\anaconda3\\Lib\\site-packages\\pymultifracs\\utils.py:76: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  return array ** exponent\n",
      "c:\\Users\\aejog\\anaconda3\\Lib\\site-packages\\pymultifracs\\cumulants.py:265: RuntimeWarning: divide by zero encountered in log\n",
      "  log_T_X_j = np.log(T_X_j)\n",
      "c:\\Users\\aejog\\anaconda3\\Lib\\site-packages\\pymultifracs\\mfspectrum.py:117: RuntimeWarning: invalid value encountered in divide\n",
      "  R_j = temp / Z\n",
      "c:\\Users\\aejog\\anaconda3\\Lib\\site-packages\\pymultifracs\\mfspectrum.py:118: RuntimeWarning: divide by zero encountered in log2\n",
      "  V[:, ind_j, :] = fixednansum(R_j * np.log2(mrq_values_j), axis=1)\n",
      "c:\\Users\\aejog\\anaconda3\\Lib\\site-packages\\pymultifracs\\mfspectrum.py:118: RuntimeWarning: invalid value encountered in multiply\n",
      "  V[:, ind_j, :] = fixednansum(R_j * np.log2(mrq_values_j), axis=1)\n",
      "c:\\Users\\aejog\\anaconda3\\Lib\\site-packages\\pymultifracs\\mfspectrum.py:119: RuntimeWarning: divide by zero encountered in log2\n",
      "  U[:, ind_j, :] = np.log2(nj) + fixednansum((R_j * np.log2(R_j)),\n",
      "c:\\Users\\aejog\\anaconda3\\Lib\\site-packages\\pymultifracs\\mfspectrum.py:119: RuntimeWarning: invalid value encountered in multiply\n",
      "  U[:, ind_j, :] = np.log2(nj) + fixednansum((R_j * np.log2(R_j)),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformations n°2: autoreg_k=3_multifracs_j1=1_j2=12 (68, 6)\n",
      "Classifier: SVM, Mean Accuracy: 0.843, Std Dev: 0.131\n",
      "Classifier: DecisionTree, Mean Accuracy: 0.813, Std Dev: 0.132\n",
      "Classifier: RandomForest, Mean Accuracy: 0.812, Std Dev: 0.115\n",
      "\n",
      "Transformations n°3: low_fourier (68, 1208)\n",
      "Classifier: SVM, Mean Accuracy: 0.736, Std Dev: 0.027\n",
      "Classifier: DecisionTree, Mean Accuracy: 0.503, Std Dev: 0.113\n",
      "Classifier: RandomForest, Mean Accuracy: 0.707, Std Dev: 0.080\n",
      "\n",
      "Transformations n°4: crosscor_autoreg_k=5_autoreg_k=3 (68, 18)\n",
      "Classifier: SVM, Mean Accuracy: 0.841, Std Dev: 0.081\n",
      "Classifier: DecisionTree, Mean Accuracy: 0.692, Std Dev: 0.136\n",
      "Classifier: RandomForest, Mean Accuracy: 0.785, Std Dev: 0.162\n",
      "\n",
      "Transformations n°5: multifracs_j1=1_j2=12 (68, 3)\n",
      "Classifier: SVM, Mean Accuracy: 0.736, Std Dev: 0.027\n",
      "Classifier: DecisionTree, Mean Accuracy: 0.634, Std Dev: 0.073\n",
      "Classifier: RandomForest, Mean Accuracy: 0.707, Std Dev: 0.041\n",
      "\n",
      "Transformations n°6: low_fourier (68, 1208)\n",
      "Classifier: SVM, Mean Accuracy: 0.736, Std Dev: 0.027\n",
      "Classifier: DecisionTree, Mean Accuracy: 0.503, Std Dev: 0.137\n",
      "Classifier: RandomForest, Mean Accuracy: 0.722, Std Dev: 0.093\n",
      "\n",
      "Transformations n°7: multifracs_j1=1_j2=12_autoencoder_fourier_transform=True (68, 19)\n",
      "Classifier: SVM, Mean Accuracy: 0.736, Std Dev: 0.027\n",
      "Classifier: DecisionTree, Mean Accuracy: 0.530, Std Dev: 0.027\n",
      "Classifier: RandomForest, Mean Accuracy: 0.665, Std Dev: 0.089\n",
      "\n",
      "Transformations n°8: shannon_encoding (68, 8)\n",
      "Classifier: SVM, Mean Accuracy: 0.736, Std Dev: 0.027\n",
      "Classifier: DecisionTree, Mean Accuracy: 0.680, Std Dev: 0.182\n",
      "Classifier: RandomForest, Mean Accuracy: 0.780, Std Dev: 0.062\n",
      "\n",
      "Transformations n°9: shannon_encoding_low_psd_autoreg_k=5_multifracs_j1=1_j2=12 (68, 1224)\n",
      "Classifier: SVM, Mean Accuracy: 0.736, Std Dev: 0.027\n",
      "Classifier: DecisionTree, Mean Accuracy: 0.604, Std Dev: 0.091\n",
      "Classifier: RandomForest, Mean Accuracy: 0.720, Std Dev: 0.060\n",
      "\n",
      "Transformations n°10: low_fourier_low_psd_crosscor (68, 2426)\n",
      "Classifier: SVM, Mean Accuracy: 0.736, Std Dev: 0.027\n",
      "Classifier: DecisionTree, Mean Accuracy: 0.518, Std Dev: 0.147\n",
      "Classifier: RandomForest, Mean Accuracy: 0.722, Std Dev: 0.093\n",
      "\n",
      "Transformations n°11: autoreg_k=5_autoreg_k=3_low_psd_crosscor (68, 1226)\n",
      "Classifier: SVM, Mean Accuracy: 0.736, Std Dev: 0.027\n",
      "Classifier: DecisionTree, Mean Accuracy: 0.589, Std Dev: 0.095\n",
      "Classifier: RandomForest, Mean Accuracy: 0.736, Std Dev: 0.056\n",
      "\n",
      "Transformations n°12: autoreg_k=3_crosscor_autoreg_k=5_autoencoder_fourier_transform=True (68, 34)\n",
      "Classifier: SVM, Mean Accuracy: 0.826, Std Dev: 0.083\n",
      "Classifier: DecisionTree, Mean Accuracy: 0.649, Std Dev: 0.134\n",
      "Classifier: RandomForest, Mean Accuracy: 0.798, Std Dev: 0.122\n",
      "\n",
      "Transformations n°13: multifracs_j1=1_j2=12_autoreg_k=3_shannon_encoding_autoencoder_fourier_transform=True (68, 30)\n",
      "Classifier: SVM, Mean Accuracy: 0.751, Std Dev: 0.030\n",
      "Classifier: DecisionTree, Mean Accuracy: 0.811, Std Dev: 0.098\n",
      "Classifier: RandomForest, Mean Accuracy: 0.799, Std Dev: 0.137\n",
      "\n",
      "Transformations n°14: multifracs_j1=1_j2=12_autoreg_k=3_crosscor (68, 16)\n",
      "Classifier: SVM, Mean Accuracy: 0.796, Std Dev: 0.049\n",
      "Classifier: DecisionTree, Mean Accuracy: 0.619, Std Dev: 0.120\n",
      "Classifier: RandomForest, Mean Accuracy: 0.782, Std Dev: 0.120\n",
      "\n",
      "Transformations n°15: multifracs_j1=1_j2=12_autoreg_k=5_autoencoder_fourier_transform=True_crosscor (68, 34)\n",
      "Classifier: SVM, Mean Accuracy: 0.765, Std Dev: 0.026\n",
      "Classifier: DecisionTree, Mean Accuracy: 0.662, Std Dev: 0.090\n",
      "Classifier: RandomForest, Mean Accuracy: 0.767, Std Dev: 0.081\n",
      "\n",
      "Transformations n°16: autoencoder_fourier_transform=True_low_psd_crosscor_autoreg_k=5 (68, 1239)\n",
      "Classifier: SVM, Mean Accuracy: 0.736, Std Dev: 0.027\n",
      "Classifier: DecisionTree, Mean Accuracy: 0.501, Std Dev: 0.115\n",
      "Classifier: RandomForest, Mean Accuracy: 0.708, Std Dev: 0.072\n",
      "\n",
      "Transformations n°17: autoencoder_fourier_transform=True_multifracs_j1=1_j2=12 (68, 19)\n",
      "Classifier: SVM, Mean Accuracy: 0.736, Std Dev: 0.027\n",
      "Classifier: DecisionTree, Mean Accuracy: 0.544, Std Dev: 0.026\n",
      "Classifier: RandomForest, Mean Accuracy: 0.651, Std Dev: 0.107\n",
      "\n",
      "Transformations n°18: autoencoder_fourier_transform=True_crosscor_shannon_encoding (68, 34)\n",
      "Classifier: SVM, Mean Accuracy: 0.736, Std Dev: 0.027\n",
      "Classifier: DecisionTree, Mean Accuracy: 0.516, Std Dev: 0.196\n",
      "Classifier: RandomForest, Mean Accuracy: 0.752, Std Dev: 0.052\n",
      "\n",
      "Transformations n°19: autoreg_k=3_crosscor_shannon_encoding (68, 21)\n",
      "Classifier: SVM, Mean Accuracy: 0.781, Std Dev: 0.059\n",
      "Classifier: DecisionTree, Mean Accuracy: 0.633, Std Dev: 0.075\n",
      "Classifier: RandomForest, Mean Accuracy: 0.797, Std Dev: 0.080\n",
      "\n",
      "Transformations n°20: low_psd_low_fourier_shannon_encoding (68, 2424)\n",
      "Classifier: SVM, Mean Accuracy: 0.736, Std Dev: 0.027\n",
      "Classifier: DecisionTree, Mean Accuracy: 0.532, Std Dev: 0.099\n",
      "Classifier: RandomForest, Mean Accuracy: 0.737, Std Dev: 0.068\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import itertools\n",
    "import json\n",
    "\n",
    "# Define the classifiers to be tested\n",
    "classifiers = {\n",
    "    'SVM': SVC(),\n",
    "    'DecisionTree': DecisionTreeClassifier(),\n",
    "    'RandomForest': RandomForestClassifier()\n",
    "}\n",
    "\n",
    "# Initialize the data transformer\n",
    "data_transformer = DataTransform(registry)\n",
    "\n",
    "# Define the transformations to be tested\n",
    "transformation_names = ['crosscor','low_psd','low_fourier',['autoreg',{'k':3}],['autoreg',{'k':5}], #'multifracs',\n",
    "                        ['multifracs', {'j1':1,'j2':j2max}],\n",
    "                        'shannon_encoding',['autoencoder',{'fourier_transform':True}]] #list(registry.transformations.keys())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to evaluate a classifier using cross-validation\n",
    "def evaluate_classifier_cv(classifier, X, y):\n",
    "    scores = cross_val_score(classifier, X, y, cv=5)  # 5-fold cross-validation\n",
    "    return np.mean(scores), np.std(scores)\n",
    "\n",
    "# Function to randomly combine transformations\n",
    "def random_combination_transformations(transformation_list, n_combinations=10):\n",
    "    # all_combinations = []\n",
    "    # for r in range(1, len(transformation_names) + 1):\n",
    "    #     combinations = list(itertools.combinations(transformation_names, r))\n",
    "    #     all_combinations.extend(combinations)\n",
    "    \n",
    "    # return random.sample(all_combinations, min(n_combinations, len(all_combinations)))\n",
    "    nb_transformation = len(transformation_list)\n",
    "    combined_transformations = []\n",
    "    for _ in range(n_combinations):\n",
    "        nb_trans = np.random.randint(1,5)\n",
    "\n",
    "        already_drawn = []\n",
    "        transs = []\n",
    "        for _ in range(nb_trans):\n",
    "            while True:\n",
    "                random_ind = np.random.randint(nb_transformation)\n",
    "                if random_ind not in already_drawn:\n",
    "                    already_drawn.append(random_ind)\n",
    "                    break\n",
    "            trans = transformation_list[random_ind]\n",
    "            transs.append(trans)\n",
    "            \n",
    "        combined_transformations.append(transs)\n",
    "    return combined_transformations\n",
    "# Generate random combinations of transformations\n",
    "random_transformations = random_combination_transformations(transformation_names, n_combinations=20)\n",
    "print(random_transformations)\n",
    "# # Example input data\n",
    "# X = np.random.randn(100, 10)  # Example input data\n",
    "# y = np.random.randint(0, 2, 100)  # Example labels\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {}\n",
    "\n",
    "i = 0\n",
    "# Loop over each random combination of transformations and each classifier\n",
    "for trans in random_transformations:\n",
    "    print()\n",
    "    trans_name_str = DataTransform.get_full_trans_kwargs_str(trans)\n",
    "    \n",
    "        \n",
    "    transformed_X = data_transformer.apply_transformation(X, trans)\n",
    "\n",
    "    # trans_name_str = '+'.join(trans_comb)\n",
    "    # transformed_X = data_transformer.apply_transformation(X, trans_comb)\n",
    "    \n",
    "    # Standardize the data (important for some classifiers like SVM)\n",
    "    scaler = StandardScaler()\n",
    "    transformed_X = scaler.fit_transform(transformed_X)\n",
    "    \n",
    "    results[trans_name_str] = {}\n",
    "    i += 1\n",
    "    print(f\"Transformations n°{i}: {trans_name_str} {transformed_X.shape}\")\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        # Evaluate the classifier with cross-validation\n",
    "        mean_accuracy, std_accuracy = evaluate_classifier_cv(clf, transformed_X, y)\n",
    "        results[trans_name_str][clf_name] = {'mean_accuracy': mean_accuracy, 'std_accuracy': std_accuracy}\n",
    "        print(f\"Classifier: {clf_name}, Mean Accuracy: {mean_accuracy:.3f}, Std Dev: {std_accuracy:.3f}\")\n",
    "\n",
    "# Save results to a JSON file\n",
    "with open('transformation_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to a JSON file\n",
    "with open('transformation_results_hrv_chall2002.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Transformation: autoreg_k=3_multifracs_j1=1_j2=12\n",
      "Best Classifier: SVM\n",
      "Best Mean Accuracy: 0.8428571428571429\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "##\n",
    "# Load the results from the JSON file\n",
    "with open('transformation_results_hrv_chall2002.json', 'r') as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "# Find the best transformation and classifier\n",
    "best_score = 0\n",
    "best_transformation = None\n",
    "best_classifier = None\n",
    "\n",
    "for trans_comb, clf_results in results.items():\n",
    "    for clf_name, scores in clf_results.items():\n",
    "        if scores['mean_accuracy'] > best_score:\n",
    "            best_score = scores['mean_accuracy']\n",
    "            best_transformation = trans_comb\n",
    "            best_classifier = clf_name\n",
    "\n",
    "print(f\"Best Transformation: {best_transformation}\")\n",
    "print(f\"Best Classifier: {best_classifier}\")\n",
    "print(f\"Best Mean Accuracy: {best_score}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
